{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f3f7bc",
   "metadata": {},
   "source": [
    "### Understanding LangChain: A Modular Framework for LLMs\n",
    "\n",
    "* LangChain is fundamentally a framework designed for Large Language Models (LLMs).\n",
    "\n",
    "* It enables the development of various applications such as chatbots, Generative Question-Answering (GQA), content summarization, and beyond.\n",
    "\n",
    "* The essence of the framework lies in its ability to \"chain\" diverse components, facilitating the creation of sophisticated functionalities utilizing LLMs.\n",
    "  * Chains are composed of various elements across different modules, including:\n",
    "\n",
    "* These are pre-designed templates tailored for specific interactions, ranging from chatbot dialogues to Explain Like I'm Five (ELI5) question-responding formats.\n",
    "\n",
    "* This encompasses a range of Large Language Models such as ChatGPT, Bard, Claude, etc.\n",
    "* Agents leverage LLMs to determine necessary actions. They can employ tools like web search or calculators, integrated into a cohesive operational loop.\n",
    "* Incorporating both short-term and long-term memory functionalities.\n",
    "\n",
    "* Our primary aim here is to delve into the functionality that enables the transformation of unstructured text into structured data, extracting valuable insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb8e12",
   "metadata": {},
   "source": [
    "### Core Components of LangChain\n",
    "\n",
    "* Chains are composed of various modules that can be combined to enhance the capabilities of LLMs.\n",
    "\n",
    "Key Modules Include:\n",
    "\n",
    "  * Prompt Templates: Customizable templates suited for different interaction styles, including chatbot  conversations.\n",
    "  * LLMs: Incorporation of various Large Language Models such as ChatGPT, Bard, Claude, etc.\n",
    "  *  Agents: Agents utilize LLMs to determine the necessary actions, employing tools like web searches or calculators within a logical operational loop.\n",
    "  * Memory Modules: These include both short-term and long-term memory functionalities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac5307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Honolulu\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1698781836,\n",
      "  \"id\": \"chatcmpl-8Fp2y37BB4XnVABL7L0yWB4Vr6tzn\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 2,\n",
      "    \"prompt_tokens\": 28,\n",
      "    \"total_tokens\": 30\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\" What is the most populated city in the state of Hawaii. \n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# openai.api_key = \"ADD API KEY HERE\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=128,\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8dbc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Honolulu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74e5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06094074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1cdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state of Hawaii. \n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57db3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2614340b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Honolulu.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8813f9dd",
   "metadata": {},
   "source": [
    "### Prompts Are First Class objects in LangChain\n",
    "\n",
    "* Prompts can be easily tailored to incorporate runtime variables.\n",
    "* They can also be customized with examples for more precise and context-relevant responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9791241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state of {state}.\n",
    "\n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c52da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5c20ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Honolulu'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Hawaii\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99901955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Los Angeles'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"California\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6045f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b8a5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state provided below.\n",
    "\n",
    "Provide city name and no additional information. \n",
    "\n",
    "Examples:\n",
    "\n",
    "State: Hawaii\n",
    "City: Honolulu\n",
    "\n",
    "State: California\n",
    "City: Los Angeles\n",
    "\n",
    "State: {state}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33f4e2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='City: Atlanta', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efcb73f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'City: Atlanta'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38054a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state provided below.\n",
    "\n",
    "Provide city name and no additional information. \n",
    "\n",
    "Examples:\n",
    "\n",
    "State: Hawaii\n",
    "{{\"City\": \"Honolulu\"}}\n",
    "\n",
    "State: California\n",
    "{{\"City\": \"Los Angeles\"}}\n",
    "\n",
    "State: {state}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c6034cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\"City\": \"Atlanta\"}', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5cfc21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"City\": \"Atlanta\"}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c313d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'City': 'Atlanta'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data = json.loads(response.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71089bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"City\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef6f587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"\"\"What is the most populated city in the state provided below. \n",
    "Provide city name and no additional information. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f910569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ExampleState': 'Hawaii', 'ExampleCity': 'Honolu'},\n",
       " {'ExampleState': 'California', 'ExampleCity': 'Los Angeles'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_examples = [\n",
    "    {\"ExampleState\": \"Hawaii\", \"ExampleCity\": \"Honolu\"},\n",
    "    {\"ExampleState\": \"California\", \"ExampleCity\": \"Los Angeles\"}   \n",
    "]\n",
    "prompt_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27eabaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: {ExampleState}\n",
      "City: {ExampleCity}\n"
     ]
    }
   ],
   "source": [
    "example_prompt_str =\"State: {ExampleState}\\nCity: {ExampleCity}\"\n",
    "print(example_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "652ecbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['ExampleState', 'ExampleCity'], output_parser=None, partial_variables={}, template='State: {ExampleState}\\nCity: {ExampleCity}', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"ExampleState\", \"ExampleCity\"], template = example_prompt_str)\n",
    "\n",
    "example_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90ae69fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: Hawaii\n",
      "City: Honolu\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.format(**prompt_examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f35ecc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: California\n",
      "City: Los Angeles\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.format(**prompt_examples[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eab28255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "execute_fewshot_prompt = FewShotPromptTemplate(\n",
    "    prefix = prompt_prefix,\n",
    "    input_variables=[\"state\"],\n",
    "    examples= prompt_examples,\n",
    "    example_prompt = example_prompt,\n",
    "    example_separator=\"\\n\\n\",\n",
    "    suffix = \"State: {state}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "827de395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n",
      "\n",
      "State: Hawaii\n",
      "City: Honolu\n",
      "\n",
      "State: California\n",
      "City: Los Angeles\n",
      "\n",
      "State: Georgia\n"
     ]
    }
   ],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93c04532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='City: Atlanta', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = execute_fewshot_prompt | model\n",
    "chain.invoke(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0508d9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " State: {ExampleState}\n",
      "  {open_curly} \"City\": \"{ExampleCity}\" {close_curly} \n"
     ]
    }
   ],
   "source": [
    "example_prompt_str_json = \"\"\" State: {ExampleState}\\n  {open_curly} \"City\": \"{ExampleCity}\" {close_curly} \"\"\"\n",
    "print(example_prompt_str_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d893123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['ExampleState', 'ExampleCity'], output_parser=None, partial_variables={'open_curly': '{{', 'close_curly': '}}'}, template=' State: {ExampleState}\\n  {open_curly} \"City\": \"{ExampleCity}\" {close_curly} ', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"ExampleState\", \"ExampleCity\"],  \n",
    "    partial_variables={\"open_curly\": \"{{\", \"close_curly\": \"}}\"},\n",
    "    template = example_prompt_str_json)\n",
    "example_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6539f41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExampleState': 'Hawaii', 'ExampleCity': 'Honolu'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "568d9004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " State: California\n",
      "  {{ \"City\": \"Los Angeles\" }} \n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.format(**prompt_examples[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7751cf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['ExampleState', 'ExampleCity'], output_parser=None, partial_variables={'open_curly': '{{', 'close_curly': '}}'}, template=' State: {ExampleState}\\n  {open_curly} \"City\": \"{ExampleCity}\" {close_curly} ', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afe47bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "execute_fewshot_prompt = FewShotPromptTemplate(\n",
    "    prefix = prompt_prefix,\n",
    "    input_variables=[\"state\"], \n",
    "\n",
    "    examples= prompt_examples,\n",
    "    example_prompt = example_prompt,\n",
    "    example_separator=\"\\n\\n\",\n",
    "    suffix = \"State: {state}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f170354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n",
      "\n",
      " State: Hawaii\n",
      "  { \"City\": \"Honolu\" } \n",
      "\n",
      " State: California\n",
      "  { \"City\": \"Los Angeles\" } \n",
      "\n",
      "State: Georgia\n"
     ]
    }
   ],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23ec6cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{ \"City\": \"Atlanta\" }', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = execute_fewshot_prompt | model\n",
    "response = chain.invoke(data)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6946f5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"City\": \"Atlanta\" }'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26cb6f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'City': 'Atlanta'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(response.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a38e3edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "465de8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fec0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityParser(BaseModel):\n",
    "    City: str = Field(..., description=\"The name of the most populous city\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b471bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "cityParser = PydanticOutputParser(pydantic_object=CityParser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d6a63fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityParser(City='Atlanta')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cityParser.parse(\"\"\"{\"City\": \"Atlanta\"}\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c40c4f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = cityParser.parse(\"\"\"{\"City\": \"Atlanta\"}\"\"\")\n",
    "output.City\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "526f5be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n",
      "\n",
      " State: Hawaii\n",
      "  { \"City\": \"Honolu\" } \n",
      "\n",
      " State: California\n",
      "  { \"City\": \"Los Angeles\" } \n",
      "\n",
      "State: Georgia\n"
     ]
    }
   ],
   "source": [
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68f655c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityParser(City='Atlanta')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "chain = execute_fewshot_prompt | model | cityParser\n",
    "reponse = chain.invoke(data)\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a778559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reponse.City\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffcc3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n",
      "\n",
      " State: Hawaii\n",
      "  { \"City\": \"Honolu\" } \n",
      "\n",
      " State: California\n",
      "  { \"City\": \"Los Angeles\" } \n",
      "\n",
      "State: Georgia\n"
     ]
    }
   ],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc303d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n"
     ]
    }
   ],
   "source": [
    "print(prompt_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3aabdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"\"\"What is the most populated city in the state provided below. \n",
    "Provide city name and no additional information. \n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9048f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n",
      "\n",
      "{format_instructions}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "607ada21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"City\": {\"description\": \"The name of the most populous city\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"City\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(cityParser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22463617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"City\": {\"description\": \"The name of the most populous city\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"City\"]}\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      " State: Hawaii\n",
      "  { \"City\": \"Honolu\" } \n",
      "\n",
      " State: California\n",
      "  { \"City\": \"Los Angeles\" } \n",
      "\n",
      "State: Georgia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_fewshot_prompt = FewShotPromptTemplate(\n",
    "    prefix = prompt_prefix,\n",
    "    input_variables=[\"state\"], \n",
    "    partial_variables={\"format_instructions\": cityParser.get_format_instructions()},\n",
    "    examples= prompt_examples,\n",
    "    example_prompt = example_prompt,\n",
    "    example_separator=\"\\n\\n\",\n",
    "    suffix = \"State: {state}\\n\"\n",
    ")\n",
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e479422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityParser(City='Atlanta')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "chain = execute_fewshot_prompt | model | cityParser\n",
    "reponse = chain.invoke(data)\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "765b0d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (0.13.3)\n",
      "Requirement already satisfied: filelock in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from huggingface_hub) (3.12.2)\n",
      "Requirement already satisfied: requests in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from huggingface_hub) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from huggingface_hub) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from huggingface_hub) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "774bec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2dfcc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "repo_id_flan = \"google/flan-t5-xxl\" \n",
    "\n",
    "\n",
    "llm_google_flan = HuggingFaceHub(\n",
    "    repo_id= repo_id_flan, model_kwargs={\"temperature\": 1, \"max_length\": 64},\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcaf5717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'Georgia'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9db2ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"City\": {\"description\": \"The name of the most populous city\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"City\"]}\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      " State: Hawaii\n",
      "  { \"City\": \"Honolu\" } \n",
      "\n",
      " State: California\n",
      "  { \"City\": \"Los Angeles\" } \n",
      "\n",
      "State: Georgia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5e44dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | llm_google_flan \n",
    "reponse = chain.invoke(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0057d8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"City\": \"Atlanta\"'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9562ce4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"City\": \"Atlanta\" } \\n\\nState: Texas\\n{ \"City'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "# repo_id_llama_2 = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "repo_id_mistral = \"mistralai/Mistral-7B-Instruct-v0.1\" \n",
    "\n",
    "\n",
    "llm_mistral = HuggingFaceHub(\n",
    "    repo_id= repo_id_mistral, model_kwargs={\"temperature\": 1, \"max_length\": 64},\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN\n",
    ")\n",
    "\n",
    "chain = execute_fewshot_prompt | llm_mistral\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67a26958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"City\": \"Atlanta\" } '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = execute_fewshot_prompt | llm_mistral.bind(stop=\"\\n\")\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1288cbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityParser(City='Atlanta')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = execute_fewshot_prompt | llm_mistral.bind(stop=\"\\n\") | cityParser\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fae18d17",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Ollama\nmodel_kwargs\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [87], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackManager\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_stdout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StreamingStdOutCallbackHandler\n\u001b[0;32m----> 5\u001b[0m ollama_llama_llm \u001b[38;5;241m=\u001b[39m \u001b[43mOllama\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallbackManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mStreamingStdOutCallbackHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/temp/lib/python3.9/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/temp/lib/python3.9/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Ollama\nmodel_kwargs\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "# from langchain.llms import Ollama\n",
    "# from langchain.callbacks.manager import CallbackManager\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# ollama_llama_llm = Ollama(\n",
    "#     model=\"llama2\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cdd76eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'Georgia'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d411c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can help you with that! The most populated city in the state provided is:\n",
      "\n",
      "{ \"City\": \"Los Angeles\" }"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure, I can help you with that! The most populated city in the state provided is:\\n\\n{ \"City\": \"Los Angeles\" }'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = execute_fewshot_prompt | ollama_llama_llm\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db999c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f51bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
