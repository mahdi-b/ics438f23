{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "901a2fe4",
   "metadata": {},
   "source": [
    "At its core, LangChain is a framework built around LLMs. \n",
    "\n",
    "We can use it for chatbots, Generative Question-Answering (GQA), summarization, and much more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "* At its core, LangChain is a framework built around LLMs. \n",
    "\n",
    "* We can use it for chatbots, Generative Question-Answering (GQA), summarization, and much more.\n",
    "\n",
    "* The core idea of the library is that we can “chain” together different components to create more advanced use cases around LLMs.\n",
    "\n",
    "* Chains may consist of multiple components from several modules:\n",
    "\n",
    "* Prompt templates: Prompt templates are templates for different types of prompts. Like “chatbot” style templates, ELI5 question-answering, etc\n",
    "\n",
    "* LLMs: Large language models like ChatGPT, Bard, Claude, etc.\n",
    "\n",
    "* Agents: Agents use LLMs to decide what actions should be taken. Tools like web search or calculators can be used, and all are packaged into a logical loop of operations.\n",
    "\n",
    "* Memory: Short-term memory, long-term memory.\n",
    "\n",
    "* Here we will only introduce the functionlity that will allow us to turn unstrctued to structured text to get insigh form it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16463fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic usage is simlar to what we've done in the previous session.\n",
    "\n",
    "1. Build a prompt\n",
    "2. Feed the prompt an LLM\n",
    "3. Get the results back\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" What is the most populated city in the state of Hawaii. \n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# openai.api_key = \"ADD API KEY HERE\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=128,\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8dbc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06094074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state of Hawaii. \n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb485f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompts Are First Class objects in LangChain\n",
    "\n",
    "* Prompt can be easily customized to take run time variable.\n",
    "* Can be customized with exmaples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state of {state}.\n",
    "\n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"state\": \"Hawaii\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99901955",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"state\": \"California\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6045f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state provided below.\n",
    "\n",
    "Provide city name and no additional information. \n",
    "\n",
    "Examples:\n",
    "\n",
    "State: Hawaii\n",
    "City: Honolulu\n",
    "\n",
    "State: California\n",
    "City: Los Angeles\n",
    "\n",
    "State: {state}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f4e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38054a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state provided below.\n",
    "\n",
    "Provide city name and no additional information. \n",
    "\n",
    "Examples:\n",
    "\n",
    "State: Hawaii\n",
    "{{\"City\": \"Honolulu\"}}\n",
    "\n",
    "State: California\n",
    "{{\"City\": \"Los Angeles\"}}\n",
    "\n",
    "State: {state}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6034cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cfc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c313d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.loads(response.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71089bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"City\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"\"\"What is the most populated city in the state provided below. \n",
    "Provide city name and no additional information. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f910569",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples = [\n",
    "    {\"ExampleState\": \"Hawaii\", \"ExampleCity\": \"Honolu\"},\n",
    "    {\"ExampleState\": \"California\", \"ExampleCity\": \"Los Angeles\"}   \n",
    "]\n",
    "prompt_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eabaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_str =\"State: {ExampleState}\\nCity: {ExampleCity}\"\n",
    "print(example_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ecbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"ExampleState\", \"ExampleCity\"], template = example_prompt_str)\n",
    "example_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_prompt.format(**prompt_examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_prompt.format(**prompt_examples[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab28255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "execute_fewshot_prompt = FewShotPromptTemplate(\n",
    "    prefix = prompt_prefix,\n",
    "    input_variables=[\"state\"],\n",
    "    examples= prompt_examples,\n",
    "    example_prompt = example_prompt,\n",
    "    example_separator=\"\\n\\n\",\n",
    "    suffix = \"State: {state}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827de395",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c04532",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | model\n",
    "chain.invoke(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_str_json = \"\"\" State: {ExampleState}\\n  {open_curly} \"City\": \"{ExampleCity}\" {close_curly} \"\"\"\n",
    "print(example_prompt_str_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d893123",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"ExampleState\", \"ExampleCity\"],  \n",
    "    partial_variables={\"open_curly\": \"{{\", \"close_curly\": \"}}\"},\n",
    "    template = example_prompt_str_json)\n",
    "example_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_prompt.format(**prompt_examples[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7751cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe47bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "execute_fewshot_prompt = FewShotPromptTemplate(\n",
    "    prefix = prompt_prefix,\n",
    "    input_variables=[\"state\"], \n",
    "\n",
    "    examples= prompt_examples,\n",
    "    example_prompt = example_prompt,\n",
    "    example_separator=\"\\n\\n\",\n",
    "    suffix = \"State: {state}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f170354",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec6cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | model\n",
    "response = chain.invoke(data)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(response.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465de8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityParser(BaseModel):\n",
    "    City: str = Field(..., description=\"The name of the most populous city\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "cityParser = PydanticOutputParser(pydantic_object=CityParser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cityParser.parse(\"\"\"{\"City\": \"Atlanta\"}\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c4f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cityParser.parse(\"\"\"{\"City\": \"Atlanta\"}\"\"\")\n",
    "output.City\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "chain = execute_fewshot_prompt | model | cityParser\n",
    "reponse = chain.invoke(data)\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a778559",
   "metadata": {},
   "outputs": [],
   "source": [
    "reponse.City\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc303d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aabdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"\"\"What is the most populated city in the state provided below. \n",
    "Provide city name and no additional information. \n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22463617",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_fewshot_prompt = FewShotPromptTemplate(\n",
    "    prefix = prompt_prefix,\n",
    "    input_variables=[\"state\"], \n",
    "    partial_variables={\"format_instructions\": cityParser.get_format_instructions()},\n",
    "    examples= prompt_examples,\n",
    "    example_prompt = example_prompt,\n",
    "    example_separator=\"\\n\\n\",\n",
    "    suffix = \"State: {state}\\n\"\n",
    ")\n",
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774bec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "\n",
    "# HUGGINGFACEHUB_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "repo_id_flan = \"google/flan-t5-xxl\" \n",
    "\n",
    "\n",
    "llm_google_flan = HuggingFaceHub(\n",
    "    repo_id= repo_id_flan, model_kwargs={\"temperature\": 1, \"max_length\": 64},\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e44dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | llm_google_flan \n",
    "reponse = chain.invoke(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "# repo_id_Llama_2 = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "repo_id_mistral = \"mistralai/Mistral-7B-Instruct-v0.1\" \n",
    "\n",
    "\n",
    "llm_google_mistral = HuggingFaceHub(\n",
    "    repo_id= repo_id_mistral, model_kwargs={\"temperature\": 0.1, \"max_length\": 64},\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN\n",
    ")\n",
    "\n",
    "chain = execute_fewshot_prompt | llm_google_mistral \n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fea2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a26958",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | llm_google_mistral.bind(stop=\"\\n\")\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | llm_google_mistral.bind(stop=\"\\n\") | cityParser\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab61222d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a1ff3d8",
   "metadata": {},
   "source": [
    "- thoughts: Can you do receipts with one or do you need multiple prompts?\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
