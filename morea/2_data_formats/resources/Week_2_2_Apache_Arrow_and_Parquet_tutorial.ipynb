{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eb47fc",
   "metadata": {},
   "source": [
    "### Introduction to PyArrow\n",
    "\n",
    "*   PyArrow serves as a cross-language development environment specifically designed for in-memory data.\n",
    "*   Its primary goal is to boost the performance of analytics applications.\n",
    "*   Emerging from the Apache Arrow project, PyArrow aims to make data interoperability better across different languages and systems.\n",
    "*   It uses an in-memory columnar data representation, offering an optimized memory footprint for complex data structures.\n",
    "*   With zero-copy reads, it facilitates quick data sharing between Python and other languages, sidestepping the need for serialization.\n",
    "*   It supports schemas and metadata, providing data structures that are rich and self-describing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3013192",
   "metadata": {},
   "source": [
    "### PyArrow and Parquet\n",
    "\n",
    "*   PyArrow offers seamless reading and writing operations for Parquet files.\n",
    "*   With column pruning, you can selectively read only the necessary columns from a Parquet file, reducing I/O time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq \n",
    "table = pq.read_table('your_file.parquet', columns=['column1', 'column2']) \n",
    "# Potentially conver the file to pandas if needed for more sophisticated splicing and dicing.\n",
    "df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46b332",
   "metadata": {},
   "source": [
    "### Apache Arrow\n",
    "\n",
    "```The core feature of Apache Arrow is its in-memory columnar format. This language-agnostic standard is designed to store structured, table-like datasets efficiently in memory. The data format supports a rich set of data types, including nested and user-defined types, making it suitable for analytic databases, data frame libraries, and more.``` \n",
    "\n",
    "The Apache Arrow Project\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebcdbec",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://blog.djnavarro.net/posts/2021-11-19_starting-apache-arrow-in-r/img/with_arrow.jpg\" width=700>\n",
    "</div>\n",
    "\n",
    "[picture source](https://blog.djnavarro.net/posts/2021-11-19_starting-apache-arrow-in-r/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyarrow`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac5bc2",
   "metadata": {},
   "source": [
    "### PyArrow Data Structures\n",
    "\n",
    "*   PyArrow offers a suite of low-level data structures and methods optimized for both speed and flexibility.\n",
    "*   These structures can be used seamlessly across multiple languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57327800",
   "metadata": {},
   "source": [
    "### Arrow Array\n",
    "\n",
    "*   An Arrow Array is essentially a column of data stored in an efficient, contiguous block of memory.\n",
    "*   Unlike Python lists, these arrays are optimized for high-speed operations and can be transferred across languages without incurring serialization costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22df9c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyarrow.lib.Int64Array'>\n",
      "---------\n",
      "[\n",
      "  1,\n",
      "  2,\n",
      "  3,\n",
      "  4,\n",
      "  5\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "arrow_array = pa.array([1, 2, 3, 4, 5])\n",
    "print(type(arrow_array))\n",
    "print(\"---------\")\n",
    "print(arrow_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcda45",
   "metadata": {},
   "source": [
    "### Arrow Buffer\n",
    "\n",
    "* While not a data structure per se, Arrow Buffers are pivotal in understanding Arrow functionality.\n",
    "* Buffers are blocks of memory that house the data for Arrow Arrays, contributing to efficient storage.\n",
    "* You can even access the buffer's content directly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35754c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyarrow.Buffer address=0x59974030140 size=40 is_cpu=True is_mutable=True>\n"
     ]
    }
   ],
   "source": [
    "buffer = arrow_array.buffers()[1]\n",
    "print(buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c81af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "byte_data = buffer.to_pybytes()\n",
    "print(byte_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed66a0",
   "metadata": {},
   "source": [
    "### Arrow Buffer - Cont'd\n",
    "\n",
    "* Here, the buffer's data contains 40 bytes, each 8 bytes representing an `int64` value for each of the 5 elements in the array.\n",
    "* You can use this buffer data to create a new NumPy array, showing that Arrow and NumPy can share memory.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d462d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "numpy_array = np.frombuffer(buffer, dtype=np.int64)\n",
    "numpy_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "983cb2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(arrow_array, numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac880c9",
   "metadata": {},
   "source": [
    "### Arrow Buffer - Cont'd\n",
    "\n",
    "* Both `arrow_array` and `numpy_array` share the same underlying data, demonstrating the concept of zero-copy.\n",
    "* You can confirm this by modifying a value in one array and seeing the change in the other.\n",
    "  * Both arrays will now show the updated value.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d6df885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 4, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array[1] = 0\n",
    "numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78887976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.Int64Array object at 0x105c51340>\n",
       "[\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  5\n",
       "]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrow_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b45749",
   "metadata": {},
   "source": [
    "### Schema\n",
    "\n",
    "* A schema in PyArrow defines the structure, column names, and types for Arrow Arrays.\n",
    "* Schemas are crucial as they set the framework for data manipulation and operations in Arrow.\n",
    "  * Give Arrow an idea on how to encode the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "186b4447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column1: int64\n",
      "column2: string\n"
     ]
    }
   ],
   "source": [
    "schema = pa.schema([('column1', pa.int64()), ('column2', pa.string())])\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd46394",
   "metadata": {},
   "source": [
    "### Chunked Array\n",
    "\n",
    "*   A Chunked Array in PyArrow is like a single Arrow Array but divided into smaller \"chunks.\"\n",
    "*   This structure allows for the storage and processing of datasets that are too large to fit in memory.\n",
    "*   It's commonly used in distributed computing frameworks and data streaming scenarios.\n",
    "\n",
    "* For example:\n",
    "  * you could have data sent in chunks to optimize throughput\n",
    "  * you might have multiple nodes in a distributed system each producing Arrow Arrays that are collected and represented as a ChunkedArray by the master node.\n",
    "\n",
    "* From a user perspective, a Chunked Array appears as a contiguous sequence of data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4c3087a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.ChunkedArray object at 0x1269cc3b0>\n",
       "[\n",
       "  [\n",
       "    0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4\n",
       "  ],\n",
       "  [\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_node_1 = pa.array([0,1,2,3,4])\n",
    "results_node_2 = pa.array([5,6,7,8,9,10])\n",
    "chunked_array = pa.chunked_array([results_node_1, results_node_2])\n",
    "chunked_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be520fe2",
   "metadata": {},
   "source": [
    "### Chunked Array - Cont'd\n",
    "\n",
    "* You can index into a single position or even across multiple chunks, making the data handling more versatile.\n",
    "* You can also access individual chunks, allowing for parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87d579f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.ChunkedArray object at 0x1269cc4a0>\n",
       "[\n",
       "  [\n",
       "    3,\n",
       "    4\n",
       "  ],\n",
       "  [\n",
       "    5\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_array[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "356cedc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.Int64Array object at 0x1268b69a0>\n",
       "[\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4\n",
       "]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_array.chunk(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f948c663",
   "metadata": {},
   "source": [
    "### Table\n",
    "\n",
    "* A Table in PyArrow is a container for multiple Arrow ChunkedArrays with a common schema.\n",
    "* Each column in the Table is an Arrow ChunkedArray, and all columns share the same length.\n",
    "* Tables offer an ideal format for handling data in the form of a dataframe.\n",
    "* Tables can also be partitioned across multiple files for large-scale storage, or to be sent across a network, or even to be stored in-memory on a single machine.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98dc32df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "column1: int64\n",
       "column2: string\n",
       "----\n",
       "column1: [[0,1,2,3,4]]\n",
       "column2: [[\"a\",\"b\",\"c\",\"d\",\"e\"]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column1 = pa.array([0, 1, 2, 3, 4]) \n",
    "column2 = pa.array(['a', 'b', 'c', 'd', 'e'])\n",
    "table = pa.table({'column1': column1, 'column2': column2})  \n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdaa066",
   "metadata": {},
   "source": [
    "### Record Batch\n",
    "\n",
    "*   A Record Batch is a collection of Arrow Arrays (columns) with the same length, all of which are bundled together with a schema.\n",
    "*   Much like a Chunked Array is a collection of Arrow Arrays, a Table in Apache Arrow is a collection of Record Batches.\n",
    "\n",
    "* Conceptual Relationship\n",
    "  *   In Apache Arrow, the concept of a Record Batch is to a Table what an Arrow Array is to a Chunked Array.\n",
    "    *   Arrays can be grouped together to form a Chunked Array.\n",
    "    *   Record Batches can be grouped together to form a Table.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec7454b",
   "metadata": {},
   "source": [
    "### Record Batch - Cont'd\n",
    "\n",
    "* Use Cases\n",
    "  *   The choice between using a Record Batch or a Table often depends on your specific needs. E.g.:\n",
    "    \n",
    "  *  Streaming Data: If you need to process data on-the-fly, perhaps in a streaming application where you want to process each chunk as it arrives, Record Batches are a good choice.\n",
    "    *   You can serialize and process each Record Batch independently as they arrive, without having to wait for the entire data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5606ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.RecordBatch\n",
      "column1: int64\n",
      "column2: string\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column1_array = pa.array([1, 2, 3, 4, 5])\n",
    "column2_array = pa.array(['a', 'b', 'c', 'd', 'e'])\n",
    "schema = pa.schema([('column1', pa.int64()), ('column2', pa.string())])\n",
    "\n",
    "record_batch = pa.record_batch([column1_array, column2_array], schema=schema)\n",
    "record_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18702115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyarrow.lib.Int64Array object at 0x1269a54c0>\n",
       " [\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5\n",
       " ],\n",
       " <pyarrow.lib.StringArray object at 0x1269a5100>\n",
       " [\n",
       "   \"a\",\n",
       "   \"b\",\n",
       "   \"c\",\n",
       "   \"d\",\n",
       "   \"e\"\n",
       " ]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_batch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48fe3e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.Int64Array object at 0x1269b1fa0>\n",
       "[\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5\n",
       "]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_batch[\"column1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "359f94f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "column1: int64\n",
       "column2: string\n",
       "----\n",
       "column1: [[1,2,3,4,5],[6,7,8,9,10]]\n",
       "column2: [[\"a\",\"b\",\"c\",\"d\",\"e\"],[\"f\",\"g\",\"h\",\"i\",\"j\"]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "column1_array_new = pa.array([6, 7, 8, 9, 10])\n",
    "column2_array_new = pa.array(['f', 'g', 'h', 'i', 'j'])\n",
    "record_batch_new = pa.record_batch([column1_array_new, column2_array_new], schema=schema)\n",
    "\n",
    "\n",
    "table = pa.Table.from_batches([record_batch, record_batch_new], schema=schema)\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf06e41",
   "metadata": {},
   "source": [
    "### Record Batch - Cont'd\n",
    "\n",
    "* In the example above, two Record Batches are combined to create a single Table. \n",
    "  * This is analogous to how individual Arrow Arrays can be combined to create a Chunked Array\n",
    "  * Reinforces the idea that a Record Batch is to a Table what an Arrow Array is to a Chunked Array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede8f6b",
   "metadata": {},
   "source": [
    "### Dive Into Real Data: Parquet and Memory Efficiency\n",
    "\n",
    "1.  Let's get hands-on and read a Parquet file using Apache Arrow.\n",
    "2.  Take note: the size of the data when using PyArrow is substantially smaller than a Pandas DataFrame for the same data.\n",
    "3.  Think of this as a little teaser to whet your appetite for data science goodness.\n",
    "\n",
    "**Note**: Here, I'm using the `parquet` module from the PyArrow package. This module knows how to read Parquet files among other things.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adaeb94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "hvfhs_license_num: string\n",
       "dispatching_base_num: string\n",
       "originating_base_num: string\n",
       "request_datetime: timestamp[us]\n",
       "on_scene_datetime: timestamp[us]\n",
       "pickup_datetime: timestamp[us]\n",
       "dropoff_datetime: timestamp[us]\n",
       "PULocationID: int64\n",
       "DOLocationID: int64\n",
       "trip_miles: double\n",
       "trip_time: int64\n",
       "base_passenger_fare: double\n",
       "tolls: double\n",
       "bcf: double\n",
       "sales_tax: double\n",
       "congestion_surcharge: double\n",
       "airport_fee: double\n",
       "tips: double\n",
       "driver_pay: double\n",
       "shared_request_flag: string\n",
       "shared_match_flag: string\n",
       "access_a_ride_flag: string\n",
       "wav_request_flag: string\n",
       "wav_match_flag: string\n",
       "----\n",
       "hvfhs_license_num: [[\"HV0003\",\"HV0003\",\"HV0003\",\"HV0003\",\"HV0005\",...,\"HV0005\",\"HV0003\",\"HV0005\",\"HV0005\",\"HV0005\"],[\"HV0003\",\"HV0005\",\"HV0003\",\"HV0003\",\"HV0003\",...,\"HV0003\",\"HV0003\",\"HV0003\",\"HV0003\",\"HV0003\"],...,[\"HV0005\",\"HV0005\",\"HV0005\",\"HV0003\",\"HV0003\",...,\"HV0003\",\"HV0003\",\"HV0003\",\"HV0003\",\"HV0003\"],[\"HV0003\",\"HV0005\",\"HV0003\",\"HV0003\",\"HV0003\",...,\"HV0003\",\"HV0003\",\"HV0003\",\"HV0003\",\"HV0005\"]]\n",
       "dispatching_base_num: [[\"B03404\",\"B03404\",\"B03404\",\"B03404\",\"B03406\",...,\"B03406\",\"B03404\",\"B03406\",\"B03406\",\"B03406\"],[\"B03404\",\"B03406\",\"B03404\",\"B03404\",\"B03404\",...,\"B03404\",\"B03404\",\"B03404\",\"B03404\",\"B03404\"],...,[\"B03406\",\"B03406\",\"B03406\",\"B03404\",\"B03404\",...,\"B03404\",\"B03404\",\"B03404\",\"B03404\",\"B03404\"],[\"B03404\",\"B03406\",\"B03404\",\"B03404\",\"B03404\",...,\"B03404\",\"B03404\",\"B03404\",\"B03404\",\"B03406\"]]\n",
       "originating_base_num: [[\"B03404\",\"B03404\",\"B03404\",\"B03404\",null,...,null,\"B03404\",null,null,null],[\"B03404\",null,\"B03404\",\"B03404\",\"B03404\",...,\"B03404\",\"B03404\",\"B03404\",\"B03404\",\"B03404\"],...,[null,null,null,\"B03404\",\"B03404\",...,\"B03404\",\"B03404\",\"B03404\",\"B03404\",\"B03404\"],[\"B03404\",null,\"B03404\",\"B03404\",\"B03404\",...,\"B03404\",\"B03404\",\"B03404\",\"B03404\",null]]\n",
       "request_datetime: [[2022-06-01 00:15:35.000000,2022-06-01 00:39:04.000000,2022-06-01 00:27:53.000000,2022-06-01 00:48:15.000000,2022-06-01 00:04:51.000000,...,2022-06-01 09:27:01.000000,2022-06-01 09:10:29.000000,2022-06-01 08:51:09.000000,2022-06-01 09:14:34.000000,2022-06-01 09:39:53.000000],[2022-06-01 09:15:07.000000,2022-06-01 09:37:37.000000,2022-06-01 09:17:57.000000,2022-06-01 09:02:01.000000,2022-06-01 09:22:55.000000,...,2022-06-01 14:33:14.000000,2022-06-01 14:02:15.000000,2022-06-01 14:30:21.000000,2022-06-01 14:16:09.000000,2022-06-01 14:28:30.000000],...,[2022-06-30 16:03:07.000000,2022-06-30 16:23:58.000000,2022-06-30 16:48:38.000000,2022-06-30 16:18:52.000000,2022-06-30 16:37:05.000000,...,2022-06-30 21:47:53.000000,2022-06-30 21:10:29.000000,2022-06-30 21:16:48.000000,2022-06-30 21:28:51.000000,2022-06-30 21:43:34.000000],[2022-06-30 21:50:10.000000,2022-06-30 21:38:54.000000,2022-06-30 21:37:35.000000,2022-06-30 21:14:54.000000,2022-06-30 21:49:59.000000,...,2022-06-30 23:20:49.000000,2022-06-30 23:36:13.000000,2022-06-30 23:50:50.000000,2022-06-30 23:02:40.000000,2022-06-30 23:00:28.000000]]\n",
       "on_scene_datetime: [[2022-06-01 00:17:20.000000,2022-06-01 00:40:36.000000,2022-06-01 00:31:34.000000,2022-06-01 00:49:38.000000,null,...,null,2022-06-01 09:12:34.000000,null,null,null],[2022-06-01 09:15:46.000000,null,2022-06-01 09:21:35.000000,2022-06-01 09:05:21.000000,2022-06-01 09:25:11.000000,...,2022-06-01 14:34:13.000000,2022-06-01 14:10:04.000000,2022-06-01 14:35:24.000000,2022-06-01 14:18:34.000000,2022-06-01 14:29:51.000000],...,[null,null,null,2022-06-30 16:25:34.000000,2022-06-30 16:39:05.000000,...,2022-06-30 21:50:19.000000,2022-06-30 21:16:34.000000,2022-06-30 21:20:52.000000,2022-06-30 21:31:48.000000,2022-06-30 21:44:12.000000],[2022-06-30 21:54:20.000000,null,2022-06-30 21:38:44.000000,2022-06-30 21:16:41.000000,2022-06-30 21:54:09.000000,...,2022-06-30 23:24:23.000000,2022-06-30 23:39:12.000000,2022-06-30 23:55:11.000000,2022-06-30 23:04:58.000000,null]]\n",
       "pickup_datetime: [[2022-06-01 00:17:41.000000,2022-06-01 00:42:37.000000,2022-06-01 00:36:22.000000,2022-06-01 00:51:18.000000,2022-06-01 00:13:33.000000,...,2022-06-01 09:30:54.000000,2022-06-01 09:12:38.000000,2022-06-01 09:04:49.000000,2022-06-01 09:20:02.000000,2022-06-01 09:44:46.000000],[2022-06-01 09:17:46.000000,2022-06-01 09:38:31.000000,2022-06-01 09:22:00.000000,2022-06-01 09:05:31.000000,2022-06-01 09:26:04.000000,...,2022-06-01 14:35:32.000000,2022-06-01 14:10:14.000000,2022-06-01 14:36:04.000000,2022-06-01 14:18:43.000000,2022-06-01 14:32:11.000000],...,[2022-06-30 16:08:46.000000,2022-06-30 16:28:06.000000,2022-06-30 16:58:02.000000,2022-06-30 16:25:42.000000,2022-06-30 16:40:48.000000,...,2022-06-30 21:51:26.000000,2022-06-30 21:17:21.000000,2022-06-30 21:22:53.000000,2022-06-30 21:32:20.000000,2022-06-30 21:45:36.000000],[2022-06-30 21:56:21.000000,2022-06-30 21:41:17.000000,2022-06-30 21:39:34.000000,2022-06-30 21:18:28.000000,2022-06-30 21:55:55.000000,...,2022-06-30 23:24:43.000000,2022-06-30 23:39:20.000000,2022-06-30 23:57:12.000000,2022-06-30 23:06:44.000000,2022-06-30 23:03:06.000000]]\n",
       "dropoff_datetime: [[2022-06-01 00:25:41.000000,2022-06-01 00:56:32.000000,2022-06-01 00:45:31.000000,2022-06-01 01:11:15.000000,2022-06-01 00:17:27.000000,...,2022-06-01 09:41:04.000000,2022-06-01 09:14:46.000000,2022-06-01 09:16:44.000000,2022-06-01 09:34:10.000000,2022-06-01 10:01:02.000000],[2022-06-01 09:24:48.000000,2022-06-01 09:58:51.000000,2022-06-01 10:07:51.000000,2022-06-01 09:54:00.000000,2022-06-01 09:34:02.000000,...,2022-06-01 14:57:26.000000,2022-06-01 14:31:23.000000,2022-06-01 14:57:52.000000,2022-06-01 14:28:05.000000,2022-06-01 15:00:40.000000],...,[2022-06-30 16:19:05.000000,2022-06-30 16:45:30.000000,2022-06-30 17:25:43.000000,2022-06-30 16:36:19.000000,2022-06-30 16:48:40.000000,...,2022-06-30 21:58:39.000000,2022-06-30 21:43:31.000000,2022-06-30 21:30:31.000000,2022-06-30 21:43:01.000000,2022-06-30 21:52:27.000000],[2022-06-30 22:03:42.000000,2022-06-30 21:56:58.000000,2022-06-30 21:53:26.000000,2022-06-30 21:49:15.000000,2022-06-30 22:33:30.000000,...,2022-06-30 23:38:19.000000,2022-06-30 23:51:10.000000,2022-07-01 00:07:07.000000,2022-06-30 23:26:28.000000,2022-06-30 23:18:13.000000]]\n",
       "PULocationID: [[234,161,231,87,137,...,97,23,85,72,72],[141,164,138,145,173,...,141,140,168,236,239],...,[248,208,208,107,230,...,161,68,158,158,186],[246,66,252,188,76,...,74,224,231,234,244]]\n",
       "DOLocationID: [[114,151,87,225,162,...,65,23,39,72,89],[237,140,164,174,56,...,75,168,260,238,232],...,[208,208,168,230,161,...,164,37,158,164,246],[48,232,121,76,148,...,224,13,231,48,242]]\n",
       "trip_miles: [[1.5,4.18,2.91,5.45,1.069,...,1.151,0.35,2.211,1.456,1.978],[0.53,2.602,8.81,13.26,1.15,...,2.69,3.81,5.77,1.57,6.96],...,[4.159,2.513,6.552,1.32,0.9,...,1.11,7.06,1.2,1.49,0.97],[0.81,2.443,6.31,5.97,13.53,...,6.07,4.9,0.53,2.85,6.207]]\n",
       "..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "table = pq.read_table('/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.parquet')\n",
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95e46add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.03908724244684"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(table) / 1024 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc4504cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.64825439453125 gigabytes\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import psutil\n",
    "# def print_mem():\n",
    "#     gig = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 3\n",
    "#     print(f\"{gig} gigabytes\")\n",
    "\n",
    "# print_mem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b0e7e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.87973692920059"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.parquet')\n",
    "sys.getsizeof(df) / 1024 / 1024 / 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f4201f",
   "metadata": {},
   "source": [
    "\n",
    "### Apache Arrow Datasets\n",
    "\n",
    "\n",
    "*   Datasets in PyArrow let you work with large tabular data, even when it's larger than your machine's memory\n",
    "*   It offers lazy data access, meaning you don't have to load the entire dataset into memory.\n",
    "*   Datasets support data discovery, partitioning, and compatibility with various file systems like AWS, Google Cloud, and local storage.\n",
    "  * I can read from AWS or Google without having to install anything.\n",
    "\n",
    "* import the dataset library as:\n",
    "\n",
    "```python\n",
    "import pyarrow.dataset as ds\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50e765",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "* Provider: New York City Taxi and Limousine Commission (TLC)\n",
    "* Data hosted on AWS. The URSA-LAB company account.\n",
    "* Contains data on millions of taxi and limousine trips in NYC\n",
    "* Time Period: 2009 to 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00b42c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE 2009/\r\n",
      "                           PRE 2010/\r\n",
      "                           PRE 2011/\r\n",
      "                           PRE 2012/\r\n",
      "                           PRE 2013/\r\n",
      "                           PRE 2014/\r\n",
      "                           PRE 2015/\r\n",
      "                           PRE 2016/\r\n",
      "                           PRE 2017/\r\n",
      "                           PRE 2018/\r\n",
      "                           PRE 2019/\r\n"
     ]
    }
   ],
   "source": [
    "# **Note**: In the AWS S3 listing, \"PRE\" stands for \"prefix,\" essentially representing a folder or directory.\n",
    "\n",
    "!aws s3 ls \"s3://ursa-labs-taxi-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4c3ab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE 01/\r\n",
      "                           PRE 02/\r\n",
      "                           PRE 03/\r\n",
      "                           PRE 04/\r\n",
      "                           PRE 05/\r\n",
      "                           PRE 06/\r\n",
      "                           PRE 07/\r\n",
      "                           PRE 08/\r\n",
      "                           PRE 09/\r\n",
      "                           PRE 10/\r\n",
      "                           PRE 11/\r\n",
      "                           PRE 12/\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls \"s3://ursa-labs-taxi-data/2009/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3da9fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 126 ms, total: 230 ms\n",
      "Wall time: 4.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyarrow._dataset.FileSystemDataset at 0x15be82f40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import pyarrow.dataset as ds\n",
    "dataset = ds.dataset(\"s3://ursa-labs-taxi-data/\", partitioning=[\"year\", \"month\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60be24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdea9bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ursa-labs-taxi-data/2009/01/data.parquet',\n",
       " 'ursa-labs-taxi-data/2009/02/data.parquet',\n",
       " 'ursa-labs-taxi-data/2009/03/data.parquet',\n",
       " 'ursa-labs-taxi-data/2009/04/data.parquet',\n",
       " 'ursa-labs-taxi-data/2009/05/data.parquet',\n",
       " 'ursa-labs-taxi-data/2009/06/data.parquet',\n",
       " 'ursa-labs-taxi-data/2009/07/data.parquet',\n",
       " 'ursa-labs-taxi-data/2009/08/data.parquet',\n",
       " 'ursa-labs-taxi-data/2009/09/data.parquet',\n",
       " 'ursa-labs-taxi-data/2009/10/data.parquet']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d2e4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.compute.Expression ((year == 2009) and (month == 1))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's how to load just one file (a fragment) and its schema:\n",
    "\n",
    "frag = next(dataset.get_fragments())\n",
    "frag.partition_expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d98407",
   "metadata": {},
   "source": [
    "#### Play with a Single File\n",
    "\n",
    "* Let's read in the data from this single fragment\n",
    "* Take a look at the data\n",
    "* List of column names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd4124c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.47 s, sys: 4.86 s, total: 11.3 s\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "vendor_id: string\n",
       "pickup_at: timestamp[us]\n",
       "dropoff_at: timestamp[us]\n",
       "passenger_count: int8\n",
       "trip_distance: float\n",
       "pickup_longitude: float\n",
       "pickup_latitude: float\n",
       "rate_code_id: null\n",
       "store_and_fwd_flag: string\n",
       "dropoff_longitude: float\n",
       "dropoff_latitude: float\n",
       "payment_type: string\n",
       "fare_amount: float\n",
       "extra: float\n",
       "mta_tax: float\n",
       "tip_amount: float\n",
       "tolls_amount: float\n",
       "total_amount: float\n",
       "----\n",
       "vendor_id: [[\"VTS\",\"VTS\",\"VTS\",\"DDS\",\"DDS\",...,\"DDS\",\"CMT\",\"CMT\",\"CMT\",\"CMT\"],[\"CMT\",\"DDS\",\"DDS\",\"CMT\",\"DDS\",...,\"CMT\",\"CMT\",\"CMT\",\"CMT\",\"CMT\"],...,[\"CMT\",\"CMT\",\"DDS\",\"CMT\",\"CMT\",...,\"VTS\",\"CMT\",\"VTS\",\"VTS\",\"VTS\"],[\"VTS\",\"VTS\",\"VTS\",\"VTS\",\"VTS\",...,\"VTS\",\"VTS\",\"CMT\",\"VTS\",\"CMT\"]]\n",
       "pickup_at: [[2009-01-04 02:52:00.000000,2009-01-04 03:31:00.000000,2009-01-03 15:43:00.000000,2009-01-01 20:52:58.000000,2009-01-24 16:18:23.000000,...,2009-01-01 22:42:49.000000,2009-01-04 18:27:32.000000,2009-01-04 11:48:33.000000,2009-01-04 23:21:04.000000,2009-01-04 16:11:27.000000],[2009-01-04 21:54:44.000000,2009-01-02 15:41:33.000000,2009-01-02 13:20:36.000000,2009-01-04 14:00:03.000000,2009-01-28 13:53:51.000000,...,2009-01-25 10:50:39.000000,2009-01-25 11:49:11.000000,2009-01-21 12:47:20.000000,2009-01-25 13:20:23.000000,2009-01-30 12:53:03.000000],...,[2009-01-21 08:17:06.000000,2009-01-20 20:09:15.000000,2009-01-09 19:14:11.000000,2009-01-20 21:02:47.000000,2009-01-21 08:37:05.000000,...,2009-01-25 00:04:00.000000,2009-01-01 01:30:02.000000,2009-01-25 14:40:00.000000,2009-01-22 20:46:00.000000,2009-01-25 13:07:00.000000],[2009-01-25 06:39:00.000000,2009-01-25 15:00:00.000000,2009-01-25 10:11:00.000000,2009-01-25 04:19:00.000000,2009-01-23 19:59:00.000000,...,2009-01-27 14:36:00.000000,2009-01-27 13:56:00.000000,2009-01-23 08:39:44.000000,2009-01-24 23:05:00.000000,2009-01-23 14:39:02.000000]]\n",
       "dropoff_at: [[2009-01-04 03:02:00.000000,2009-01-04 03:38:00.000000,2009-01-03 15:57:00.000000,2009-01-01 21:14:00.000000,2009-01-24 16:24:56.000000,...,2009-01-01 23:01:49.000000,2009-01-04 18:31:39.000000,2009-01-04 11:54:40.000000,2009-01-04 23:24:16.000000,2009-01-04 16:24:19.000000],[2009-01-04 21:58:25.000000,2009-01-02 15:45:22.000000,2009-01-02 13:32:59.000000,2009-01-04 14:03:02.000000,2009-01-28 14:02:28.000000,...,2009-01-25 10:52:42.000000,2009-01-25 12:07:32.000000,2009-01-21 13:01:08.000000,2009-01-25 13:24:09.000000,2009-01-30 12:59:29.000000],...,[2009-01-21 09:16:34.000000,2009-01-20 20:12:52.000000,2009-01-09 19:27:18.000000,2009-01-20 21:18:31.000000,2009-01-21 08:40:51.000000,...,2009-01-25 00:23:00.000000,2009-01-01 01:49:06.000000,2009-01-25 14:48:00.000000,2009-01-22 20:53:00.000000,2009-01-25 13:20:00.000000],[2009-01-25 06:44:00.000000,2009-01-25 15:04:00.000000,2009-01-25 10:16:00.000000,2009-01-25 04:33:00.000000,2009-01-23 20:14:00.000000,...,2009-01-27 14:46:00.000000,2009-01-27 14:02:00.000000,2009-01-23 09:02:15.000000,2009-01-24 23:15:00.000000,2009-01-23 15:35:15.000000]]\n",
       "passenger_count: [[1,3,5,1,1,...,1,1,1,1,2],[2,2,2,1,2,...,2,2,1,1,1],...,[1,1,1,1,1,...,5,2,5,1,5],[5,1,1,5,1,...,5,1,1,3,1]]\n",
       "trip_distance: [[2.63,4.55,10.35,5,0.4,...,3.7,0.9,0.5,1.1,1.3],[1.1,0.6,0.9,1.2,1,...,1,6.8,1.3,0.7,1],...,[20.7,0.2,2.1,2.3,0.5,...,5.2,4.3,0.86,1.62,1.53],[1.43,0.58,1.36,3.02,2.91,...,0.89,1.94,3.8,3.85,17.3]]\n",
       "pickup_longitude: [[-73.99196,-73.9821,-74.00259,-73.974266,-74.00158,...,-73.992744,-73.99128,-73.98005,-73.97288,-73.9776],[-73.9908,-73.975716,-73.97441,-73.97065,-73.990135,...,-73.97786,-73.95457,0,-73.97422,-73.966644],...,[-73.78204,-73.98393,-73.979645,-73.99633,-73.98092,...,-73.97414,-73.982925,-73.953926,-73.999596,-73.99288],[-73.970604,-73.99453,-73.9917,-74.00047,-73.99772,...,-73.98201,-73.972786,-73.97747,-73.98129,0]]\n",
       "pickup_latitude: [[40.721565,40.73629,40.739746,40.790955,40.719383,...,40.713802,40.723892,40.754658,40.79333,40.752],[40.751076,40.748226,40.76322,40.752747,40.740852,...,40.74217,40.78086,0,40.783566,40.804012],...,[40.644768,40.749287,40.7554,40.737335,40.76395,...,40.78377,40.73503,40.76648,40.733482,40.72419],[40.76505,40.75172,40.739643,40.728706,40.72436,...,40.74333,40.76199,40.75186,40.753,0]]\n",
       "rate_code_id: [65536 nulls,65536 nulls,...,65536 nulls,2173 nulls]\n",
       "store_and_fwd_flag: [[null,null,null,null,null,...,null,null,null,null,null],[null,null,null,null,null,...,null,null,null,null,null],...,[null,null,null,null,null,...,null,null,null,null,null],[null,null,null,null,null,...,null,null,null,null,null]]\n",
       "dropoff_longitude: [[-73.993805,-73.95585,-73.86998,-73.99656,-74.00838,...,-73.98663,-73.98523,-73.98596,-73.981995,-73.99347],[-74.00014,-73.97249,-73.98696,-73.98271,-73.99506,...,-73.98757,-73.93975,0,-73.982,-73.95343],...,[-73.96209,-73.98791,-74.005585,-73.97921,-73.98632,...,-73.917816,-73.96772,-73.96618,-74.00464,-74.00712],[-73.980606,-74.00163,-73.97803,-73.97005,-73.98376,...,-73.99433,-73.95148,-74.00991,-73.949455,0]]\n",
       "..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "frag_table = frag.to_table()\n",
    "frag_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ed59a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vendor_id',\n",
       " 'pickup_at',\n",
       " 'dropoff_at',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'pickup_longitude',\n",
       " 'pickup_latitude',\n",
       " 'rate_code_id',\n",
       " 'store_and_fwd_flag',\n",
       " 'dropoff_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'total_amount']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag_table.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c8e2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14092413"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag_table.num_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a546d3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "vendor_id: string\n",
       "pickup_at: timestamp[us]\n",
       "dropoff_at: timestamp[us]\n",
       "passenger_count: int8\n",
       "trip_distance: float\n",
       "pickup_longitude: float\n",
       "pickup_latitude: float\n",
       "rate_code_id: null\n",
       "store_and_fwd_flag: string\n",
       "dropoff_longitude: float\n",
       "dropoff_latitude: float\n",
       "payment_type: string\n",
       "fare_amount: float\n",
       "extra: float\n",
       "mta_tax: float\n",
       "tip_amount: float\n",
       "tolls_amount: float\n",
       "total_amount: float\n",
       "----\n",
       "vendor_id: [[\"VTS\",\"VTS\",\"VTS\",\"DDS\",\"DDS\",...,\"DDS\",\"CMT\",\"CMT\",\"CMT\",\"CMT\"],[\"CMT\",\"DDS\",\"DDS\",\"CMT\",\"DDS\",...,\"CMT\",\"CMT\",\"CMT\",\"CMT\",\"CMT\"],...,[\"CMT\",\"CMT\",\"DDS\",\"CMT\",\"CMT\",...,\"VTS\",\"CMT\",\"VTS\",\"VTS\",\"VTS\"],[\"VTS\",\"VTS\",\"VTS\",\"VTS\",\"VTS\",...,\"VTS\",\"VTS\",\"CMT\",\"VTS\",\"CMT\"]]\n",
       "pickup_at: [[2009-01-04 02:52:00.000000,2009-01-04 03:31:00.000000,2009-01-03 15:43:00.000000,2009-01-01 20:52:58.000000,2009-01-24 16:18:23.000000,...,2009-01-01 22:42:49.000000,2009-01-04 18:27:32.000000,2009-01-04 11:48:33.000000,2009-01-04 23:21:04.000000,2009-01-04 16:11:27.000000],[2009-01-04 21:54:44.000000,2009-01-02 15:41:33.000000,2009-01-02 13:20:36.000000,2009-01-04 14:00:03.000000,2009-01-28 13:53:51.000000,...,2009-01-25 10:50:39.000000,2009-01-25 11:49:11.000000,2009-01-21 12:47:20.000000,2009-01-25 13:20:23.000000,2009-01-30 12:53:03.000000],...,[2009-01-21 08:17:06.000000,2009-01-20 20:09:15.000000,2009-01-09 19:14:11.000000,2009-01-20 21:02:47.000000,2009-01-21 08:37:05.000000,...,2009-01-25 00:04:00.000000,2009-01-01 01:30:02.000000,2009-01-25 14:40:00.000000,2009-01-22 20:46:00.000000,2009-01-25 13:07:00.000000],[2009-01-25 06:39:00.000000,2009-01-25 15:00:00.000000,2009-01-25 10:11:00.000000,2009-01-25 04:19:00.000000,2009-01-23 19:59:00.000000,...,2009-01-27 14:36:00.000000,2009-01-27 13:56:00.000000,2009-01-23 08:39:44.000000,2009-01-24 23:05:00.000000,2009-01-23 14:39:02.000000]]\n",
       "dropoff_at: [[2009-01-04 03:02:00.000000,2009-01-04 03:38:00.000000,2009-01-03 15:57:00.000000,2009-01-01 21:14:00.000000,2009-01-24 16:24:56.000000,...,2009-01-01 23:01:49.000000,2009-01-04 18:31:39.000000,2009-01-04 11:54:40.000000,2009-01-04 23:24:16.000000,2009-01-04 16:24:19.000000],[2009-01-04 21:58:25.000000,2009-01-02 15:45:22.000000,2009-01-02 13:32:59.000000,2009-01-04 14:03:02.000000,2009-01-28 14:02:28.000000,...,2009-01-25 10:52:42.000000,2009-01-25 12:07:32.000000,2009-01-21 13:01:08.000000,2009-01-25 13:24:09.000000,2009-01-30 12:59:29.000000],...,[2009-01-21 09:16:34.000000,2009-01-20 20:12:52.000000,2009-01-09 19:27:18.000000,2009-01-20 21:18:31.000000,2009-01-21 08:40:51.000000,...,2009-01-25 00:23:00.000000,2009-01-01 01:49:06.000000,2009-01-25 14:48:00.000000,2009-01-22 20:53:00.000000,2009-01-25 13:20:00.000000],[2009-01-25 06:44:00.000000,2009-01-25 15:04:00.000000,2009-01-25 10:16:00.000000,2009-01-25 04:33:00.000000,2009-01-23 20:14:00.000000,...,2009-01-27 14:46:00.000000,2009-01-27 14:02:00.000000,2009-01-23 09:02:15.000000,2009-01-24 23:15:00.000000,2009-01-23 15:35:15.000000]]\n",
       "passenger_count: [[1,3,5,1,1,...,1,1,1,1,2],[2,2,2,1,2,...,2,2,1,1,1],...,[1,1,1,1,1,...,5,2,5,1,5],[5,1,1,5,1,...,5,1,1,3,1]]\n",
       "trip_distance: [[2.63,4.55,10.35,5,0.4,...,3.7,0.9,0.5,1.1,1.3],[1.1,0.6,0.9,1.2,1,...,1,6.8,1.3,0.7,1],...,[20.7,0.2,2.1,2.3,0.5,...,5.2,4.3,0.86,1.62,1.53],[1.43,0.58,1.36,3.02,2.91,...,0.89,1.94,3.8,3.85,17.3]]\n",
       "pickup_longitude: [[-73.99196,-73.9821,-74.00259,-73.974266,-74.00158,...,-73.992744,-73.99128,-73.98005,-73.97288,-73.9776],[-73.9908,-73.975716,-73.97441,-73.97065,-73.990135,...,-73.97786,-73.95457,0,-73.97422,-73.966644],...,[-73.78204,-73.98393,-73.979645,-73.99633,-73.98092,...,-73.97414,-73.982925,-73.953926,-73.999596,-73.99288],[-73.970604,-73.99453,-73.9917,-74.00047,-73.99772,...,-73.98201,-73.972786,-73.97747,-73.98129,0]]\n",
       "pickup_latitude: [[40.721565,40.73629,40.739746,40.790955,40.719383,...,40.713802,40.723892,40.754658,40.79333,40.752],[40.751076,40.748226,40.76322,40.752747,40.740852,...,40.74217,40.78086,0,40.783566,40.804012],...,[40.644768,40.749287,40.7554,40.737335,40.76395,...,40.78377,40.73503,40.76648,40.733482,40.72419],[40.76505,40.75172,40.739643,40.728706,40.72436,...,40.74333,40.76199,40.75186,40.753,0]]\n",
       "rate_code_id: [65536 nulls,65536 nulls,...,65536 nulls,2173 nulls]\n",
       "store_and_fwd_flag: [[null,null,null,null,null,...,null,null,null,null,null],[null,null,null,null,null,...,null,null,null,null,null],...,[null,null,null,null,null,...,null,null,null,null,null],[null,null,null,null,null,...,null,null,null,null,null]]\n",
       "dropoff_longitude: [[-73.993805,-73.95585,-73.86998,-73.99656,-74.00838,...,-73.98663,-73.98523,-73.98596,-73.981995,-73.99347],[-74.00014,-73.97249,-73.98696,-73.98271,-73.99506,...,-73.98757,-73.93975,0,-73.982,-73.95343],...,[-73.96209,-73.98791,-74.005585,-73.97921,-73.98632,...,-73.917816,-73.96772,-73.96618,-74.00464,-74.00712],[-73.980606,-74.00163,-73.97803,-73.97005,-73.98376,...,-73.99433,-73.95148,-74.00991,-73.949455,0]]\n",
       "..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626148d",
   "metadata": {},
   "source": [
    "#### Chunks: The Building Blocks\n",
    "\n",
    "* Remember how we talked about Arrow tables having columns that could be split into chunks? \n",
    "* If you take a look, each column is divided into 216 chunks\n",
    "  * Proving that this table is built in the way we discussed earlier.\n",
    "* Take just a slice of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b60f1dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "vendor_id: string\n",
       "pickup_at: timestamp[us]\n",
       "dropoff_at: timestamp[us]\n",
       "passenger_count: int8\n",
       "trip_distance: float\n",
       "pickup_longitude: float\n",
       "pickup_latitude: float\n",
       "rate_code_id: null\n",
       "store_and_fwd_flag: string\n",
       "dropoff_longitude: float\n",
       "dropoff_latitude: float\n",
       "payment_type: string\n",
       "fare_amount: float\n",
       "extra: float\n",
       "mta_tax: float\n",
       "tip_amount: float\n",
       "tolls_amount: float\n",
       "total_amount: float\n",
       "----\n",
       "vendor_id: [[\"VTS\",\"VTS\",\"VTS\",\"DDS\",\"DDS\"]]\n",
       "pickup_at: [[2009-01-04 02:52:00.000000,2009-01-04 03:31:00.000000,2009-01-03 15:43:00.000000,2009-01-01 20:52:58.000000,2009-01-24 16:18:23.000000]]\n",
       "dropoff_at: [[2009-01-04 03:02:00.000000,2009-01-04 03:38:00.000000,2009-01-03 15:57:00.000000,2009-01-01 21:14:00.000000,2009-01-24 16:24:56.000000]]\n",
       "passenger_count: [[1,3,5,1,1]]\n",
       "trip_distance: [[2.63,4.55,10.35,5,0.4]]\n",
       "pickup_longitude: [[-73.99196,-73.9821,-74.00259,-73.974266,-74.00158]]\n",
       "pickup_latitude: [[40.721565,40.73629,40.739746,40.790955,40.719383]]\n",
       "rate_code_id: [5 nulls]\n",
       "store_and_fwd_flag: [[null,null,null,null,null]]\n",
       "dropoff_longitude: [[-73.993805,-73.95585,-73.86998,-73.99656,-74.00838]]\n",
       "..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag_table.slice(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "423b3adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[frag_table[col_name].num_chunks for col_name in frag_table.column_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3e6dd",
   "metadata": {},
   "source": [
    "### The Essentials of Apache Arrow Tables and Record Batches\n",
    "\n",
    "*  Tables in Apache Arrow are essentially collections of record batches.\n",
    "*  You can easily pull data from columns like `payment_type`, `fare_amount`, or `tip_amount`. \n",
    "* Because we're working with a single record batch, managing the data is pretty straightforward. \n",
    "  * We'll see that each column, for instance, holds 65,536 values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf90cabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.RecordBatch\n",
       "vendor_id: string\n",
       "pickup_at: timestamp[us]\n",
       "dropoff_at: timestamp[us]\n",
       "passenger_count: int8\n",
       "trip_distance: float\n",
       "pickup_longitude: float\n",
       "pickup_latitude: float\n",
       "rate_code_id: null\n",
       "store_and_fwd_flag: string\n",
       "dropoff_longitude: float\n",
       "dropoff_latitude: float\n",
       "payment_type: string\n",
       "fare_amount: float\n",
       "extra: float\n",
       "mta_tax: float\n",
       "tip_amount: float\n",
       "tolls_amount: float\n",
       "total_amount: float"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_batch_3 = frag_table.to_batches()[3]\n",
    "record_batch_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30cbb487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_batch_3.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "136d7fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.FloatArray object at 0x1264da820>\n",
       "[\n",
       "  4.9,\n",
       "  10.5,\n",
       "  4.2,\n",
       "  8.2,\n",
       "  3.8,\n",
       "  17.8,\n",
       "  9.8,\n",
       "  6.9,\n",
       "  3.7,\n",
       "  10.5,\n",
       "  ...\n",
       "  45,\n",
       "  6.9,\n",
       "  6.2,\n",
       "  25.3,\n",
       "  5.7,\n",
       "  25.3,\n",
       "  5.3,\n",
       "  24.1,\n",
       "  6.9,\n",
       "  22.1\n",
       "]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_batch_3[\"fare_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0735bc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.FloatArray object at 0x126ac3220>\n",
       "[\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.76,\n",
       "  2.67,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5.06,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0\n",
       "]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_batch_3['tip_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8074fa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.StringArray object at 0x126ac31c0>\n",
       "[\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"Cash\",\n",
       "  \"Cash\",\n",
       "  \"Credit\",\n",
       "  \"Credit\",\n",
       "  \"Credit\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"Cash\",\n",
       "  ...\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"Cash\",\n",
       "  \"Credit\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"Credit\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"CASH\"\n",
       "]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_batch_3['payment_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75535c",
   "metadata": {},
   "source": [
    "#### PyArrow's Computational Capabilities\n",
    "\n",
    "*   PyArrow separates data storage concerns from computational functionality.    \n",
    "    * Structures like Arrow Arrays, Record Batches, and Tables handle data storage and serialization.\n",
    "    * For actual data operations, there's the `pyarrow.compute` module.\n",
    "*   The `pyarrow.compute` module offers a range of functions for filtering, transforming, and aggregating data.    \n",
    "    * While it does provide useful operations, it's not a full-blown analytical tool. \n",
    "    * For more complex tasks, you'd typically use something like Pandas or Spark.\n",
    "\n",
    "* Let's perform some computations like calculating the sum of tips and fares, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c46b7280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.FloatArray object at 0x107261400>\n",
       "[\n",
       "  4.9,\n",
       "  10.5,\n",
       "  4.2,\n",
       "  8.2,\n",
       "  4.56,\n",
       "  20.47,\n",
       "  11.8,\n",
       "  6.9,\n",
       "  3.7,\n",
       "  10.5,\n",
       "  ...\n",
       "  45,\n",
       "  6.9,\n",
       "  6.2,\n",
       "  30.359999,\n",
       "  5.7,\n",
       "  25.3,\n",
       "  6.3,\n",
       "  24.1,\n",
       "  6.9,\n",
       "  22.1\n",
       "]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.compute as pc\n",
    "pc.add(record_batch_3['tip_amount'], record_batch_3['fare_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365b652",
   "metadata": {},
   "source": [
    "* How about finding the maximum total amount for a trip, including the tip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "272d4043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.FloatScalar: 164.0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.max(pc.add(record_batch_3['tip_amount'], record_batch_3['fare_amount']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e0bcf",
   "metadata": {},
   "source": [
    "* And the average?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5162427e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.DoubleScalar: 10.015554052642983>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.mean(pc.add(record_batch_3['tip_amount'], record_batch_3['fare_amount']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a8057",
   "metadata": {},
   "source": [
    "* We can also perform operations on string data, like converting the case of `payment_type`, which has been recorded inconsistently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c4ea7d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.StringArray object at 0x126abf520>\n",
       "[\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"CREDIT\",\n",
       "  \"CREDIT\",\n",
       "  \"CREDIT\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  ...\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"CREDIT\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"CREDIT\",\n",
       "  \"CASH\",\n",
       "  \"CASH\",\n",
       "  \"CASH\"\n",
       "]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_cased_payment_type = pc.utf8_upper(record_batch_3[\"payment_type\"])\n",
    "upper_cased_payment_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3597a",
   "metadata": {},
   "source": [
    "* You can then filter data based on whether the payment type was \"CASH.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c334143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.BooleanArray object at 0x126abf100>\n",
       "[\n",
       "  true,\n",
       "  true,\n",
       "  true,\n",
       "  true,\n",
       "  false,\n",
       "  false,\n",
       "  false,\n",
       "  true,\n",
       "  true,\n",
       "  true,\n",
       "  ...\n",
       "  true,\n",
       "  true,\n",
       "  true,\n",
       "  false,\n",
       "  true,\n",
       "  true,\n",
       "  false,\n",
       "  true,\n",
       "  true,\n",
       "  true\n",
       "]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cash = pc.equal(upper_cased_payment_type, pa.scalar('CASH'))\n",
    "is_cash "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ff03b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51341"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_record_batch_3 = pc.filter(record_batch_3, is_cash)\n",
    "filtered_record_batch_3\n",
    "filtered_record_batch_3.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7912d0",
   "metadata": {},
   "source": [
    "\n",
    "#### Working with Parquet Files\n",
    "\n",
    "* You can read Parquet data into PyArrow as a ParquetDataset, and then work with it as ParquetFile Fragments.\n",
    "* Recall that: \n",
    "    * Each fragment has its own metadata, \n",
    "    * You can also get statistics about each row group within the fragment.\n",
    "      * However, it's usually more efficient to work with sorted data if you carry out frequent operations\n",
    "      * You can then save this sorted table into a new Parquet file for optimized data retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0192afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow\n",
    "pyarrow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb1e6667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa \n",
    "import pyarrow.parquet as pq\n",
    "dataset = pq.ParquetDataset('s3://ursa-labs-taxi-data/2009/', partitioning=[\"month\"])\n",
    "dataset\n",
    "print(\"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13072afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.16 s, sys: 2.73 s, total: 11.9 s\n",
      "Wall time: 1min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.UInt64Array object at 0x15be0c9a0>\n",
       "[\n",
       "  11489987,\n",
       "  3964040,\n",
       "  543513,\n",
       "  8582999,\n",
       "  11812099,\n",
       "  3708729,\n",
       "  10177659,\n",
       "  12142978,\n",
       "  4811616,\n",
       "  5665566,\n",
       "  ...\n",
       "  10604876,\n",
       "  10079366,\n",
       "  1839956,\n",
       "  4631967,\n",
       "  8528489,\n",
       "  347071,\n",
       "  3174063,\n",
       "  6071930,\n",
       "  1328472,\n",
       "  7684378\n",
       "]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "data_table = dataset.fragments[0].to_table() \n",
    "sorted_indices = pc.sort_indices(data_table, sort_keys=[(\"pickup_at\", \"ascending\"), (\"fare_amount\", \"ascending\")])\n",
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1269cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c4af0862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the instances in the order specified in the variable sorted_indices\n",
    "# i.e., sorting the data\n",
    "sorted_table = data_table.take(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ee6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pq.write_table(sorted_table, 'optimized_parquet_file.parquet', row_group_size=65536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33953a7",
   "metadata": {},
   "source": [
    "\n",
    "#### Exploring Sorted Parquet Files\n",
    "\n",
    "*   When you read the sorted table back into PyArrow, it's easier to work with.\n",
    "  * We can reach the read groups meta data and only look at those we are interested in.\n",
    "  * i.e., you can delve into the metadata to understand your data better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "836dc2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_columns': 18,\n",
       " 'num_rows': 65536,\n",
       " 'total_byte_size': 1645654,\n",
       " 'columns': [{'file_offset': 8548,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'BYTE_ARRAY',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'vendor_id',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': 'CMT',\n",
       "    'max': 'DDS',\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'BYTE_ARRAY'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 4,\n",
       "   'data_page_offset': 34,\n",
       "   'total_compressed_size': 8544,\n",
       "   'total_uncompressed_size': 9856},\n",
       "  {'file_offset': 196427,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'INT64',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'pickup_at',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': datetime.datetime(2009, 1, 1, 0, 0),\n",
       "    'max': datetime.datetime(2009, 1, 1, 4, 22, 17),\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'INT64'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 8622,\n",
       "   'data_page_offset': 101500,\n",
       "   'total_compressed_size': 187805,\n",
       "   'total_uncompressed_size': 234517},\n",
       "  {'file_offset': 406433,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'INT64',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'dropoff_at',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': datetime.datetime(2009, 1, 1, 0, 1, 13),\n",
       "    'max': datetime.datetime(2009, 1, 1, 15, 40, 42),\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'INT64'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 196535,\n",
       "   'data_page_offset': 291529,\n",
       "   'total_compressed_size': 209898,\n",
       "   'total_uncompressed_size': 242979},\n",
       "  {'file_offset': 431291,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'INT32',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'passenger_count',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': 0,\n",
       "    'max': 5,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'INT32'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 406542,\n",
       "   'data_page_offset': 406582,\n",
       "   'total_compressed_size': 24749,\n",
       "   'total_uncompressed_size': 24741},\n",
       "  {'file_offset': 506407,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'trip_distance',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': -0.0,\n",
       "    'max': 47.0,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 431389,\n",
       "   'data_page_offset': 432479,\n",
       "   'total_compressed_size': 75018,\n",
       "   'total_uncompressed_size': 75004},\n",
       "  {'file_offset': 667665,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'pickup_longitude',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': -74.77455139160156,\n",
       "    'max': 0.0,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 506503,\n",
       "   'data_page_offset': 552777,\n",
       "   'total_compressed_size': 161162,\n",
       "   'total_uncompressed_size': 161147},\n",
       "  {'file_offset': 890795,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'pickup_latitude',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': -0.0,\n",
       "    'max': 45.0639533996582,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 667764,\n",
       "   'data_page_offset': 767715,\n",
       "   'total_compressed_size': 223031,\n",
       "   'total_uncompressed_size': 223011},\n",
       "  {'file_offset': 890940,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'INT32',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'rate_code_id',\n",
       "   'is_stats_set': False,\n",
       "   'statistics': None,\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 890893,\n",
       "   'data_page_offset': 890908,\n",
       "   'total_compressed_size': 47,\n",
       "   'total_uncompressed_size': 44},\n",
       "  {'file_offset': 891054,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'BYTE_ARRAY',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'store_and_fwd_flag',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': False,\n",
       "    'min': None,\n",
       "    'max': None,\n",
       "    'null_count': 65536,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 0,\n",
       "    'physical_type': 'BYTE_ARRAY'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 891003,\n",
       "   'data_page_offset': 891018,\n",
       "   'total_compressed_size': 51,\n",
       "   'total_uncompressed_size': 48},\n",
       "  {'file_offset': 1063819,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'dropoff_longitude',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': -74.77429962158203,\n",
       "    'max': 0.0,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 891129,\n",
       "   'data_page_offset': 948931,\n",
       "   'total_compressed_size': 172690,\n",
       "   'total_uncompressed_size': 172675},\n",
       "  {'file_offset': 1299061,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'dropoff_latitude',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': -0.0,\n",
       "    'max': 45.06427764892578,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 1063920,\n",
       "   'data_page_offset': 1175981,\n",
       "   'total_compressed_size': 235141,\n",
       "   'total_uncompressed_size': 235123},\n",
       "  {'file_offset': 1320093,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'BYTE_ARRAY',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'payment_type',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': 'CASH',\n",
       "    'max': 'No Charge',\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'BYTE_ARRAY'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 1299163,\n",
       "   'data_page_offset': 1299234,\n",
       "   'total_compressed_size': 20930,\n",
       "   'total_uncompressed_size': 23899},\n",
       "  {'file_offset': 1395542,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'fare_amount',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': 2.5,\n",
       "    'max': 200.0,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 1320184,\n",
       "   'data_page_offset': 1321614,\n",
       "   'total_compressed_size': 75358,\n",
       "   'total_uncompressed_size': 75344},\n",
       "  {'file_offset': 1404159,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'extra',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': -0.0,\n",
       "    'max': 0.5,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 1395639,\n",
       "   'data_page_offset': 1395663,\n",
       "   'total_compressed_size': 8520,\n",
       "   'total_uncompressed_size': 9871},\n",
       "  {'file_offset': 1404301,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'mta_tax',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': False,\n",
       "    'min': None,\n",
       "    'max': None,\n",
       "    'null_count': 65536,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 0,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 1404250,\n",
       "   'data_page_offset': 1404265,\n",
       "   'total_compressed_size': 51,\n",
       "   'total_uncompressed_size': 48},\n",
       "  {'file_offset': 1437542,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'tip_amount',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': -0.0,\n",
       "    'max': 95.44999694824219,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 1404368,\n",
       "   'data_page_offset': 1406184,\n",
       "   'total_compressed_size': 33174,\n",
       "   'total_uncompressed_size': 56230},\n",
       "  {'file_offset': 1440678,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'tolls_amount',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': -0.0,\n",
       "    'max': 20.0,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 1437638,\n",
       "   'data_page_offset': 1437816,\n",
       "   'total_compressed_size': 3040,\n",
       "   'total_uncompressed_size': 6593},\n",
       "  {'file_offset': 1535316,\n",
       "   'file_path': '',\n",
       "   'physical_type': 'FLOAT',\n",
       "   'num_values': 65536,\n",
       "   'path_in_schema': 'total_amount',\n",
       "   'is_stats_set': True,\n",
       "   'statistics': {'has_min_max': True,\n",
       "    'min': 2.5,\n",
       "    'max': 200.0,\n",
       "    'null_count': 0,\n",
       "    'distinct_count': 0,\n",
       "    'num_values': 65536,\n",
       "    'physical_type': 'FLOAT'},\n",
       "   'compression': 'SNAPPY',\n",
       "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
       "   'has_dictionary_page': True,\n",
       "   'dictionary_page_offset': 1440774,\n",
       "   'data_page_offset': 1445004,\n",
       "   'total_compressed_size': 94542,\n",
       "   'total_uncompressed_size': 94524}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_parquet_file = pq.ParquetFile('optimized_parquet_file.parquet')\n",
    "\n",
    "rg0_metadata = optimized_parquet_file.metadata.row_group(0)\n",
    "rg0_metadata.to_dict()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3fd4dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'vendor_id'),\n",
       " (1, 'pickup_at'),\n",
       " (2, 'dropoff_at'),\n",
       " (3, 'passenger_count'),\n",
       " (4, 'trip_distance'),\n",
       " (5, 'pickup_longitude'),\n",
       " (6, 'pickup_latitude'),\n",
       " (7, 'rate_code_id'),\n",
       " (8, 'store_and_fwd_flag'),\n",
       " (9, 'dropoff_longitude'),\n",
       " (10, 'dropoff_latitude'),\n",
       " (11, 'payment_type'),\n",
       " (12, 'fare_amount'),\n",
       " (13, 'extra'),\n",
       " (14, 'mta_tax'),\n",
       " (15, 'tip_amount'),\n",
       " (16, 'tolls_amount'),\n",
       " (17, 'total_amount')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,x[\"path_in_schema\"]) for i, x in enumerate(rg0_metadata.to_dict()[\"columns\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f7785bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vendor_id': 0,\n",
       " 'pickup_at': 1,\n",
       " 'dropoff_at': 2,\n",
       " 'passenger_count': 3,\n",
       " 'trip_distance': 4,\n",
       " 'pickup_longitude': 5,\n",
       " 'pickup_latitude': 6,\n",
       " 'rate_code_id': 7,\n",
       " 'store_and_fwd_flag': 8,\n",
       " 'dropoff_longitude': 9,\n",
       " 'dropoff_latitude': 10,\n",
       " 'payment_type': 11,\n",
       " 'fare_amount': 12,\n",
       " 'extra': 13,\n",
       " 'mta_tax': 14,\n",
       " 'tip_amount': 15,\n",
       " 'tolls_amount': 16,\n",
       " 'total_amount': 17}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_2_pos = {x[\"path_in_schema\"]:i for i, x in enumerate(rg0_metadata.to_dict()[\"columns\"])}\n",
    "name_2_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a464a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found it, it's row_group 2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "col_idx = name_2_pos['pickup_at']\n",
    "\n",
    "datetime_obj = datetime.strptime(\"2009-1-1 14:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "for i in range(optimized_parquet_file.num_row_groups):\n",
    "    col_stats = optimized_parquet_file.metadata.row_group(i).column(col_idx).statistics\n",
    "    if col_stats.min <= datetime_obj <= col_stats.max:\n",
    "        print(f\"found it, it's row_group {i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bonus Questions\n",
    "* can you get the average transaction between 2:00-2:59 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef62566",
   "metadata": {},
   "outputs": [],
   "source": [
    "* Which day, on average has the highest tip? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a203d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "* Which time (hour) of the day has the highest tip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d501b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4d45c6c",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "1.  [Apache Arrow Homepage](https://arrow.apache.org/)\n",
    "2.  [PyArrow Documentation](https://arrow.apache.org/docs/python/)\n",
    "3.  [PyArrow GitHub Repository](https://github.com/apache/arrow/tree/master/python/pyarrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262ab3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
