{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "449f7aab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Popular Big Data Fromats\n",
    "\n",
    "* Data format is an important aspect of working with big data\n",
    "\n",
    "* The recurring topic is \"There ain't such a thing as free lunch\"\n",
    "\n",
    "```\"There ain't no such thing as a free lunch\", also known as \"there is no such thing as a free lunch\" (TINSTAAFL), is an expression that describes the cost of decision-making. The expression conveys the idea that things appearing free always have some cost paid by somebody.``` **https://www.investopedia.com/terms/t/tanstaafl.asp**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce05a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key Considerations for Big Data Formats\n",
    "\n",
    "* In light of the TINSTAAFL principle, the following challenges are always posed when choosing a data format for big data projects:\n",
    "* **Compression**: Different file formats offer varying levels of compressibility with specific algorithms.\n",
    "* **Splittability**: Evaluate how easily a file format can be split.\n",
    "  * As highlighted when we discussed the embarrassingly parallel paradigm, the capacity to split a file for distributed processing across multiple machines can be of critical importance.\n",
    "* **Column vs. Row Storage**: The importance of individual columns (or variables) in your dataset may vary.\n",
    "* **Data Types and Schema Evolution**:  Consider whether it's necessary to enforce data types.\n",
    "  * Given the scale of big data (think petabytes), it's unrealistic to assume files can be easily regenerated whenever schema changes occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed420e46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### File Format: an Intuition\n",
    "\n",
    "* In big data, selecting an appropriate storage format is crucial for optimizing performance, conserving storage space.\n",
    "* The right choice can lead to time savings, reduced complexity, and lower costs.\n",
    "* Most of us are familiar with row-based formats -- think MS Excel, where each row represents a table entry.\n",
    "\n",
    "| Transaction Date     | Nb Items     | Total       |\n",
    "|------------------    |----------    |---------    |\n",
    "| 01/01/2001           | 4            | 1852.14     |\n",
    "| 01/01/2001           | 3            | 968.00      |\n",
    "| ...             | ...     | ...     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8017d4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### File Format: an Intuition - Cont'd\n",
    "    \n",
    "* The current format may not be suitable for certain data types or operations.\n",
    "\n",
    "* E.g.: sales information contains an extremely large volume of daily transactions—say hundreds of thousands.\n",
    "    * Transaction dates would be redundantly repeated many times, wasting storage space.\n",
    "    * A dictionary-like format, where the key is the transaction date, might be more storage-efficient.\n",
    "\n",
    "```python\n",
    "{\"01/01/2001\": ((4, 1852.14), (3,  968.00), ...), \"01/02/2001\":(...), ... }\n",
    "```\n",
    "\n",
    "* This format would also make day-based calculations more efficient.\n",
    "  * For instance, calculating the number of transactions or total sales for each day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4e83b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### File Format: an Intuition - Cont'd\n",
    "\n",
    "* If the objective is to calculate the total sales:\n",
    "  * In a table format, sifting through millions of lines would be required to determine a single total sales figure.\n",
    "  * Using dates as keys, you'd simply index into each specific date to tally up the total sales.\n",
    "* Another option is to utilize a row-based data format.\n",
    "  * Here, reading a single line could be enough to compute the total sales.\n",
    "\n",
    "|              |      |  |   | |\n",
    "| :---              |    :----:  | :--------: | :--------: |:---:|\n",
    "| **Totals**             | 1852.14    | 968.00   | 256.21 | `...` |\n",
    "| **Transaction Dates** | 01/01/2001 | 01/01/2001 | 01/02/2001 | `...` |\n",
    "| **Nb Items**               | 4             | 3       |  2  | `...` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14cc7fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### File Formats Decisions\n",
    "\n",
    "* Four key factors should be considered when choosing file formats:\n",
    "    1. Row vs Column\n",
    "      * What types of analytics will be performed?\n",
    "    2. Schema Management\n",
    "      * Is it likely that my data schemas will change over time?\n",
    "    3. Splittability\n",
    "      * Is it possible to distribute data across multiple files or even servers?\n",
    "    4. Compression\n",
    "      * How well does the format compress?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222eba3f-4574-4cb9-9fcf-d9ead9db1924",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9dfd1dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Row- and Column-Based Formats\n",
    "\n",
    "* This is a crucial factor to consider when choosing a format for big data.\n",
    "\n",
    "![](https://www.dropbox.com/s/an5fg7xl2uvnfb8/row_col_format.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571cc57-8ee6-4147-9146-20ede8ef1e62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issue with In Memory data Layout\n",
    "\n",
    "* What's the issue when data is not stored consecutively in RAM?\n",
    "* Example: Storing rows but needing to extract a single column.\n",
    "* This makes data retrieval inefficient.\n",
    "* Buzzword Alert: It's a \"Stride\" problem!\n",
    "  * A \"stride\" is the gap between data points we're interested in.\n",
    "  * In row based data, to extract columns, we need to skip n−1 columns to get to the next data point in the column.\n",
    "  * This is called \"strided access\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6960b4a0-2719-4435-99a1-445e1c0694c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Strided Access\n",
    "\n",
    "* Consider the following dat\n",
    "* \n",
    "```python\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "```\n",
    "\n",
    "* A typical, \"non-strided\" access pattern might read every element in the array consecutively from start to finish, like so:\n",
    "```python\n",
    "1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10\n",
    "```\n",
    "\n",
    "* In a strided access pattern with a stride of 2, you would skip every other element:\n",
    "```python\n",
    "1 -> 3 -> 5 -> 7 -> 9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d8c86-e07e-406b-b914-420081be7a2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Strided Access - cont'd\n",
    "\n",
    "* you're trying to read down a single column, you'd be skipping $n−1$ elements to get to the next one in that column\n",
    "  * Strided access pattern with a stride of $n$\n",
    " \n",
    "* Strided access is generally less efficient than consecutive access due to the way CPU caching mechanisms and memory hierarchies work.\n",
    "  *  Less effective use if the cache\n",
    "  *  Potentially more time-consuming operations to retrieve the required data.\n",
    "  *  Modern CPUs love data that's close together!\n",
    "* This is a \"data locality\" problem.\n",
    "   * More time spent retrieving data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7274f5-09fa-43cd-ba4c-406aef75e922",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Caching and Performance\n",
    "\n",
    "* Caches store frequently accessed data.\n",
    "* Cache Miss occurs when the data isn't in the cache, it takes longer to fetch.\n",
    "* Strided Access often results in more cache misses.\n",
    "  * This slows down the application or system.\n",
    "* The issue is covered at lenght  in Concurrent and High-Performance Programming (ICS432),  Operating Systems (ICS332),  Machine-Level and Systems Programming (ICS312)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2bb0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Row- and Column-Based Formats\n",
    "\n",
    "* Row-based: Best suited when you need to access all the data.\n",
    "  * For instance, when constructing a machine learning model that uses all features and instances.\n",
    "    * You can sidestep loading the entire dataset into RAM by reading it in chunks (batches).\n",
    "    * This approach necessitates frequent conditional access to multiple columns.\n",
    "* Column-based storage: Ideal for colun-specific tasks.\n",
    "  * Examples include calculating total sales or even aggregating data by date, among others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b5853",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Row-Based Formats\n",
    "\n",
    "* Commonly employed in a range of mainstream applications, from web log files to structured database systems like MySQL and Oracle.\n",
    "* To process the entire dataset, one would need to read each line sequentially.\n",
    "* This format is a go-to choice for Online Transactional Processing (OLTP).\n",
    "  * OLTP systems typically handle CRUD operations (Create, Read, Update, and Delete) at the individual record level.\n",
    "  * A key focus for OLTP systems is ensuring data integrity in environments where multiple users are accessing the data.\n",
    "    * Performance in OLTP systems is generally assessed by the number of transactions executed per second.\n",
    "      * We'll delve deeper into this topic when discussing big data platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e001a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Column-Based Formats\n",
    "\n",
    "* Data is organized by columns.\n",
    "* Streamlines computation on selected columns.\n",
    "  * For example, you can easily compute the mean or standard deviation for a particular column.\n",
    "    * Why do you think this operation is more efficient in a column-based format?\n",
    "\n",
    "* Highly conducive to compression.\n",
    "  * Compression algorithms like GZIP and pkzip perform better when handling sequences of similar data types.\n",
    "\n",
    "  ```python\n",
    "  [1,2,3,...], \n",
    "  [\"John\", \"Janet\", \"Michael\", ...]\n",
    "  ```\n",
    "\n",
    "This is more efficient to compress than:\n",
    "```python\n",
    "[[1, \"John\", \"Doe\", \"125,000\"], [2, \"Janet\", \"Smith\", \"195,129\"], ...]\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38afd709-d6d1-458b-818b-4ff740d966cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Column-Based Formats\n",
    "\n",
    "* Disk and network are often the bottlenecks in large, distributed systems.\n",
    "* Employing compression minimizes read IO and data transfers, making your analysis faster.\n",
    "\n",
    "* Column-based data storage is commonly known as OLAP (Online Analytical Processing).\n",
    "  * OLAP is a computing approach designed to quickly answer multi-dimensional queries. \n",
    "  * More on OLAP when we dicuss platforms.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://www.dropbox.com/scl/fi/oqongt8biqxwzrsesl889/olap_dimensions.png?rlkey=qjlqqcby2da2qa4v1b9c7ot31&dl=1\" width=1100/> \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf15a2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compression of Row vs. Columnar Data\n",
    "\n",
    "* ** Data Homogeneity** : This means that the same compression algorithm can be applied more effectively.\n",
    "  * Example: A column with only integers can be efficiently compressed using an algorithm tailored for integers.\n",
    "* **Reduced Cardinality**: Columns often have fewer unique values.\n",
    "  * Example: Run-length encoding can be extremely effective in such cases.\n",
    "* **Range of Values**:  Columns often have a narrow range of values\n",
    "  * Example: Delta encoding could be highly effective here.\n",
    "  * initial data: `[100, 105, 110, 101, 100]` >encode> `100 [5, 10, 1, 0]`\n",
    "  * Think about `diff` in code for example.\n",
    "\n",
    "* **Pedictive models**: use predictive compresison when \"good enough\" is \"good enough\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b956e59c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 4, 1, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choices([1,2,3,4], k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a583d68",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'T', 'G', 'C', 'C', 'T']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choices(\"ACGT\", k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e5d052",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "0123456789\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "print(string.printable)\n",
    "print(string.digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0b23c8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8414\n",
      "5081\n"
     ]
    }
   ],
   "source": [
    "import zlib \n",
    "import string\n",
    "\n",
    "# let's randomly generate two string of 1000, an ASCII and an INT\n",
    "\n",
    "random_ASCII = random.choices(string.printable, k=10_000)\n",
    "random_numbers = random.choices(string.digits, k=10_000)\n",
    "print(len(zlib.compress( str.encode(\"\".join(random_ASCII)))))\n",
    "print(len(zlib.compress( str.encode(\"\".join(random_numbers)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc0f4f5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6547445239154617"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "ratios = []\n",
    "for i in range(10):\n",
    "    random_ASCII = random.choices(string.printable, k=10_000)\n",
    "    random_numbers = random.choices(string.digits, k=10_000)\n",
    "    len_ascii = len(zlib.compress( str.encode(\"\".join(random_ASCII)))) \n",
    "    len_numbers = len(zlib.compress( str.encode(\"\".join(random_numbers))))\n",
    "    ratios.append(len_ascii/len_numbers)\n",
    "    \n",
    "numpy.mean(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad2327eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f565ea35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3462144408226877"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = []\n",
    "for i in range(10):\n",
    "    random_ASCII = random.choices(string.printable, k=10_000)\n",
    "    random_uppercase = random.choices(string.ascii_uppercase, k=10_000)\n",
    "    len_ascii = len(zlib.compress( str.encode(\"\".join(random_ASCII)))) \n",
    "    len_uppercase = len(zlib.compress( str.encode(\"\".join(random_uppercase))))\n",
    "    ratios.append(len_ascii/len_uppercase)    \n",
    "numpy.mean(ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a083d77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples of OLAP versus OLTP in Amazon\n",
    "\n",
    "![](https://www.dropbox.com/s/cxhwtc5s582tnp2/amazon_olap_oltp.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2279abc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Column-based formats: Advantages and Disadvantages\n",
    "\n",
    "<u>Advantages</u>:\n",
    "* Columnar storage of data can sometimes yield 100x-1000x performance improvements, particularly for wide datasets\n",
    "\n",
    "\n",
    "<u>Disadvantages</u>:\n",
    "  *  Not efficient with CRUD operations\n",
    "  * Difficult to access all features of a single instance\n",
    "    * Need to parse all columns to read items at position $i$\n",
    "  * Hard to read by a human\n",
    "  * Can be more CPU intensive to write for very large data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a4a3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2- Datatype and Schema Enforcement and Evolution\n",
    "\n",
    "* \"Schema\" in a database context, means the structure and organization of the data  \n",
    "    * Structure: datatypes, missing values, primary keys, etc, indices, etc.\n",
    "    * Organization: relationships across tables.\n",
    "\n",
    "* Here, we mainly refer to the data type\n",
    "* In text format, (e.g.: table with values separated by space), datatype cannot be declared or enforced\n",
    "\n",
    "* Declaring the type of a value provides some advantages.\n",
    "  * Storage requirements: String categories will require more storage than boolean (2 bytes)\n",
    "  * Data validity: Verifies the dataset is valid and prevents entry errors (e.g., age = Johnn)\n",
    "  * Compression: there are good strategies for compressing different data types "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c5229",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2- Datatype & Schema Enforcement and Evolution - Cont'd\n",
    "\n",
    "\n",
    "* In the event that there is no guarantee that data won't change in the future, you may need to consider schema evolution.\n",
    "\n",
    "\n",
    "* When evaluating schema evolution, there are a few key questions to ask of any data format:\n",
    "  * How easy is it to update a schema (such as adding a field, removing or renaming a field)?\n",
    "  * How will different versions of the schema impact applications?\n",
    "  * How fast can the schema be processed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5de7933",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3- Splitability\n",
    "\n",
    "* Big data such as monthly logs, yearly transactions, daily airplane sensors recordings, can often comprise many millions of records.\n",
    "\n",
    "* Often useful to split the data across multiple machines and execute each computation separately\n",
    "\n",
    "* Some file formats are more amenable to splitting than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebb546",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3- Splitability - Row-Based\n",
    "\n",
    "Row-based formats can be split along row boundaries\n",
    "\n",
    "```\n",
    "# file 1 with n lines\n",
    "01/01/2001           4            1852.14\n",
    "01/01/2001           3            968.00\n",
    "...\n",
    "```\n",
    "\n",
    "* Splitting can be done\n",
    "  * Randomly plitting `file 1` with `n` observations across `m` total machines is easy.\n",
    "\n",
    "    * Each machine gets `ceiling(n/m)` unique lines, last machine gets remaining lines\n",
    "\n",
    " * Splitting based on one or more fields: \n",
    "    * Partitioning a rown-based file over particular column values can be difficult if data is stored in a random order.\n",
    "    * May require sorting the data first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f3d5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3- Splitability: Row-Based, Nested \n",
    "\n",
    "* Larg column-based data can be more difficult to split\n",
    "\n",
    "``` \n",
    "file 2\n",
    "{\"01/01/20014\": [(4, 1852.14), (3, 968.00)], ....}\n",
    "```\n",
    "\n",
    "* You cannot easily split this file this file format without parsing the file first.\n",
    "  * Need to read the compelte file to split it into chunks.\n",
    "    * Data may need to ne loaded in RAM first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aad4d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3- Splitability: Column-Based, Nested\n",
    "\n",
    "\n",
    "* A column-based format can be split if the comutation is column-specific.\n",
    "\n",
    "```\n",
    "# file 3\n",
    "date: 01/01/2001, 01/01/2001\n",
    "nb_items: 4, 3\n",
    "totals: 1852.14, 968.00\n",
    "```\n",
    "\n",
    "Splitting can only e done column-wise:\n",
    "* In the example above, each machine is concerned with a computation on a specific variable. For example:\n",
    "  * Machine 1 takes `date` data and computes the number of sales per month\n",
    "  * Machine 2 takes the `nb_items` data and computes the total number of sales\n",
    "  * Machine 3 takes the `totals` data and computes the total sales values\n",
    " \n",
    "* Machines don't have any knowledge of variables that are not given.\n",
    "  * E.g., if machine three is not given date info and cannot compute, for example, the monthly or weekly sales average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e3a8c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4- Compression\n",
    "\n",
    "\n",
    "* When working on a distributed system, data transfer can be a serious bottleneck\n",
    "* Compression can substantially improve runtime and storage requirements\n",
    "\n",
    "* We illustrated \"naively\" that columnar data can achieve better compression rates than row-based data\n",
    "  * Simple way to think about it: column will have a lot more duplicate values:\n",
    "      * Ex. Age Column: 21, 22, 21, 24, 25, 21, 22, 21, 19, 21, 21, 22, ....\n",
    "      \n",
    "* Note that complex compression algorithms on very large files can save on space but substantially increase compute time.\n",
    "    * Uncompression/re-compression needs to occur every time you need to access the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6279c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standardization and File Formats\n",
    "\n",
    "* One can always choose their own format for the file\n",
    "  * Many companies may choose to do so internally for many reasons.\n",
    "  * E.g.:\n",
    "\n",
    "```\n",
    "FIRST_NAME_1\\sLAST_NAME_1\\tFIRST_NAME_2\\sLAST_NAME_2\\tFIRST_NAME_3\\sLAST_NAME_3...\n",
    "JOBTITLE_1\\sSALARY_1\\tJOBTITLE_2\\sSALARY_2\\tJOBTITLE_3\\sSALARY_3\n",
    "```\n",
    "\n",
    "* However, there are many benefits to using a standard file format. E.g.:\n",
    "  * Clarity and productivity: eliminating the need for guesswork or extra searching for answer. Plus there is no need to maintain internal documentation, which makes it easier to get answers online when issues arise.\n",
    "\n",
    "  * Quality: standard formats are designed by large teams and used extensively, which provides opportunities to optimize them\n",
    "\n",
    "  * Interoperability: your data is no longer locked to your company (or compartmentalized) and can be used across platforms.\n",
    "\n",
    "* Some of the most used formats are CSV, JSON, Parquet, AVRO, HDF5\n",
    "  * All very well supported in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0ff77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CSV File Format\n",
    "\n",
    "* Files in the CSV (Comma-separated values) format are usually used to exchange tabular data\n",
    "  * Plain-text file (readable characters)\n",
    " \n",
    "* CSV is a row-based file format: each row of the file is a separate data instance\n",
    "  * May or may not contain a header\n",
    "* Structure is conveyed through explicit commas\n",
    "  * Text commas are encapsulated in double quotes\n",
    "\n",
    "```\n",
    "Title,Author,Genre,Height,Publisher\n",
    "\"Computer Vision, A Modern Approach\",\"Forsyth, David\",data_science,255,Pearson\n",
    "Data Mining Handbook,\"Nisbet, Robert\",data_science,242,Apress\n",
    "Making Software,\"Oram, Andy\",computer_science,232,O'Reilly\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae2028",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CSV File Format\n",
    "\n",
    "* CSV format is not fully standardized\n",
    "  * Other characters can be used to separate files, such as tabs (tsv) or spaces (ssv)\n",
    " \n",
    "* Data relationships across multiple CSV files are not expressed in the file format\n",
    "  * Use same column names to indicate \"foreign key\" relationship\n",
    " \n",
    "\n",
    "* Native support in Python\n",
    "```python\n",
    "import csv\n",
    "csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "# use csv ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a5b2c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0: {'Rank': '1', 'Year': '2009', 'Movie': 'Avatar', 'WorldwideBox Office': '$2,845,899,541', 'DomesticBox Office': '$760,507,625', 'InternationalBox Office': '$2,085,391,916'}\n",
      "Line 1: {'Rank': '2', 'Year': '2019', 'Movie': 'Avengers: Endgame', 'WorldwideBox Office': '$2,797,800,564', 'DomesticBox Office': '$858,373,000', 'InternationalBox Office': '$1,939,427,564'}\n",
      "Line 2: {'Rank': '3', 'Year': '1997', 'Movie': 'Titanic', 'WorldwideBox Office': '$2,207,986,545', 'DomesticBox Office': '$659,363,944', 'InternationalBox Office': '$1,548,622,601'}\n",
      "Line 3: {'Rank': '4', 'Year': '2015', 'Movie': 'Star Wars Ep. VII: The Force Awakens', 'WorldwideBox Office': '$2,064,615,817', 'DomesticBox Office': '$936,662,225', 'InternationalBox Office': '$1,127,953,592'}\n",
      "Line 4: {'Rank': '5', 'Year': '2018', 'Movie': 'Avengers: Infinity War', 'WorldwideBox Office': '$2,044,540,523', 'DomesticBox Office': '$678,815,482', 'InternationalBox Office': '$1,365,725,041'}\n",
      "Line 5: {'Rank': '6', 'Year': '2015', 'Movie': 'Jurassic World', 'WorldwideBox Office': '$1,669,979,967', 'DomesticBox Office': '$652,306,625', 'InternationalBox Office': '$1,017,673,342'}\n",
      "Line 6: {'Rank': '7', 'Year': '2019', 'Movie': 'The Lion King', 'WorldwideBox Office': '$1,654,367,425', 'DomesticBox Office': '$543,638,043', 'InternationalBox Office': '$1,110,729,382'}\n",
      "Line 7: {'Rank': '8', 'Year': '2015', 'Movie': 'Furious 7', 'WorldwideBox Office': '$1,516,881,526', 'DomesticBox Office': '$353,007,020', 'InternationalBox Office': '$1,163,874,506'}\n",
      "Line 8: {'Rank': '9', 'Year': '2012', 'Movie': 'The Avengers', 'WorldwideBox Office': '$1,515,100,211', 'DomesticBox Office': '$623,357,910', 'InternationalBox Office': '$891,742,301'}\n",
      "Line 9: {'Rank': '10', 'Year': '2019', 'Movie': 'Frozen II', 'WorldwideBox Office': '$1,446,925,396', 'DomesticBox Office': '$477,373,578', 'InternationalBox Office': '$969,551,818'}\n"
     ]
    }
   ],
   "source": [
    "# All_Time_Worldwide_Box_Office_partial.csv\n",
    "import csv\n",
    "with open('data/All_Time_Worldwide_Box_Office.csv')  as csvfile:\n",
    "    movies_file = csv.DictReader(csvfile, delimiter=',', quotechar='\"')\n",
    "    i = 0 \n",
    "    for line in movies_file:\n",
    "        print(f\"Line {i}: {line}\")\n",
    "        i+=1\n",
    "        if i ==10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a748ae3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CSV Pros and Cons\n",
    "<u>Pros:</u>\n",
    "* Human-readable and easy to edit manually\n",
    "* Provides a simple scheme\n",
    "* Can be processed by almost all existing applications\n",
    "* Easy to implement and parse;\n",
    "* Compact (compared to, for instance JSON or MXL)\n",
    "* Column headers are written only once\n",
    "\n",
    "<u>Cons:</u>\n",
    "* No guarantees about data integrity, i.e., data won't be missing or won't be in a different type than expected.\n",
    "* Adding complex structures to a data structure is not possible\n",
    "  * May need to reference other files to implement nesting\n",
    "* There is no standard way to present binary data\n",
    "* Lack of a universal standard can cause "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb872ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### JSON File Format\n",
    "\n",
    "* JSON (JavaScript Object Notation)\n",
    "* Open standard file format that uses human-readable text\n",
    "  * FIle typically stored using `.json` extension\n",
    "* Became popular as a space-saving alternative to Extensible Markup Language (XML)\n",
    "* Inspired by JavaScript objects but is a language-independent data format\n",
    "* Very similar to the combination of Python's lists and dicts\n",
    "* Also supported natively in Python\n",
    "  \n",
    "```python\n",
    "import json\n",
    "json.load(...)\n",
    "```\n",
    "\n",
    "* The defacto language of the web\n",
    "  * Supported in all modern languages and particularly web languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11c99f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### JSON File Structure\n",
    "\n",
    "* JSON supports the following types.\n",
    "\n",
    "* Scalar values\n",
    "    * `Numbers`: e.g. 3\n",
    "    * `String`: Sequence of Unicode characters surrounded by double quotation marks.\n",
    "    * `Boolean`: `true` or `false`.\n",
    "\n",
    "* Collections:\n",
    "    * `Array`: A list of values surrounded by square brackets `[]`\n",
    "    * `Dictionaries`: key\" value pairs separated by a comma(,) and enclosed in `{}`\n",
    "      * Keys are strings and values can be any valid scalar or collection\n",
    "* [See the following for more details](https://docs.fileformat.com/web/json/)\n",
    "* [See the following very good (useful) validator for validating JSON files or records](https://jsonformatter.curiousconcept.com/#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16187bc2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'First Name': 'John',\n",
       "  'Occupation': 'Student',\n",
       "  'Salary': 120000,\n",
       "  'volunteer': False},\n",
       " {'First Name': 'John',\n",
       "  'Occupation': 'Student',\n",
       "  'salary': None,\n",
       "  'volunteer': True}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = [ \n",
    "    {'First Name': \"John\", \"Occupation\": \"Student\", \"Salary\": 120_000, \"volunteer\": False}, \n",
    "    {'First Name': \"John\", \"Occupation\": \"Student\", \"salary\": None, \"volunteer\": True}\n",
    "]\n",
    "my_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c69d70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "json.load\n",
    "json.loads\n",
    "json.dump\n",
    "json.dumps\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cd4c7b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"First Name\": \"John\", \"Occupation\": \"Student\", \"Salary\": 120000, \"volunteer\": false}, {\"First Name\": \"John\", \"Occupation\": \"Student\", \"salary\": null, \"volunteer\": true}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_representation = json.dumps(my_data)\n",
    "print(json_representation)\n",
    "# Note the changes between the Python dict and the JSON string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42c6ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Working with the Python `json` library\n",
    "\n",
    "\n",
    "* `All_Time_Worldwide_Box_Office_partial.json`  structure\n",
    "```json\n",
    "[\n",
    " {\n",
    "  \"Rank\": \"1\",\n",
    "  \"Year\": \"2009\",\n",
    "  \"Movie\": \"Avatar\",\n",
    "  \"WorldwideBox Office\": \"$2,845,899,541\",\n",
    "  \"DomesticBox Office\": \"$760,507,625\",\n",
    "  \"InternationalBox Office\": \"$2,085,391,916\"\n",
    " },\n",
    " {\n",
    "  \"Rank\": \"2\",\n",
    "  \"Year\": \"2019\",\n",
    "  \"Movie\": \"Avengers: Endgame\",\n",
    "  \"WorldwideBox Office\": \"$2,797,800,564\",\n",
    "  \"DomesticBox Office\": \"$858,373,000\",\n",
    "  \"InternationalBox Office\": \"$1,939,427,564\"\n",
    " },\n",
    " ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b546b462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Rank': '1',\n",
       "  'Year': '2009',\n",
       "  'Movie': 'Avatar',\n",
       "  'WorldwideBox Office': '$2,845,899,541',\n",
       "  'DomesticBox Office': '$760,507,625',\n",
       "  'InternationalBox Office': '$2,085,391,916'},\n",
       " {'Rank': '2',\n",
       "  'Year': '2019',\n",
       "  'Movie': 'Avengers: Endgame',\n",
       "  'WorldwideBox Office': '$2,797,800,564',\n",
       "  'DomesticBox Office': '$858,373,000',\n",
       "  'InternationalBox Office': '$1,939,427,564'},\n",
       " {'Rank': '3',\n",
       "  'Year': '1997',\n",
       "  'Movie': 'Titanic',\n",
       "  'WorldwideBox Office': '$2,207,986,545',\n",
       "  'DomesticBox Office': '$659,363,944',\n",
       "  'InternationalBox Office': '$1,548,622,601'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json_file = open('data/All_Time_Worldwide_Box_Office_partial.json') \n",
    "movies_data = json.load(json_file)\n",
    "movies_data[0:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7341ee4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movies_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5c94f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movies_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac5ab41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie Avatar, grossed $2,845,899,541 in 2009\n",
      "The movie Avengers: Endgame, grossed $2,797,800,564 in 2019\n",
      "The movie Titanic, grossed $2,207,986,545 in 1997\n",
      "The movie Star Wars Ep. VII: The Force Awakens, grossed $2,064,615,817 in 2015\n",
      "The movie Avengers: Infinity War, grossed $2,044,540,523 in 2018\n",
      "The movie Jurassic World, grossed $1,669,979,967 in 2015\n",
      "The movie The Lion King, grossed $1,654,367,425 in 2019\n",
      "The movie Furious 7, grossed $1,516,881,526 in 2015\n",
      "The movie The Avengers, grossed $1,515,100,211 in 2012\n",
      "The movie Frozen II, grossed $1,446,925,396 in 2019\n"
     ]
    }
   ],
   "source": [
    "for record in movies_data:\n",
    "    print(f\"The movie {record['Movie']}, grossed {record['WorldwideBox Office']} in {record['Year']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2091ef8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### JSON Pros and Cons\n",
    "\n",
    "* Pros:\n",
    "    * Very well supported in modern languages, technologies and infrastructures\n",
    "    * Can be used as the basis for more performance-optimized formats Parquet or Avro (discussed next)\n",
    "    * Supports hierarchical structures abstracting the need for complex relationships\n",
    "    * The *defacto* standard in NoSQL databases\n",
    "* Cons:\n",
    "    * Much smaller footprint than XML but still fairly large due to repeated field names\n",
    "    * Not easy to index\n",
    "    * Some tentatives to add a schema but not commonly used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d7204",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AVRO File Format\n",
    "\n",
    "* AVRO is an advanced form of the JSON format\n",
    "  * Leverages some of the advantages of JSON while mitigating some of its disadvantages\n",
    "* Stores both a file definition (a schema itself written in JSON) and a binary format\n",
    "  * Said to be self-descriptive because it can include the schema and documentation in the header of the file containing the data\n",
    "* Serializes the data in a compact binary format\n",
    "  \n",
    "* Released by the Hadoop working group in 2009 to use with Hadoop Systems\n",
    "* It is a row-based format that has a high degree of splitting\n",
    "* Provides mechanism to manage schema evolution\n",
    "* support for most modern languages, including Python via the `avro` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51046a4-4f5f-44af-b5ab-b2e604938022",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### AVRO Schema\n",
    "{\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"Student\",\n",
    "  \"namespace\": \"hawaii.edu\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"first_name\",\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"last_name\",\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"major\",\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"DOB\",\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"student_id\",\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c387d57-118c-4be2-9c27-0b252b8bd3f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AVRO Data\n",
    "\n",
    "* For fixed-length types like integers, floats, or fixed-length arrays, we know the exact number of bytes to read. \n",
    " * For instance, a 32-bit integer will always be 4 bytes.\n",
    " * In text numbers or other data types are often represented as human-readable text\n",
    "   *  4162554 takes seven bytes in a text-based format like JSON (4, 1, 6, 2, 5, 5, 4).\n",
    "*  For variable-length data types like strings, Avro typically uses a length-prefix encoding.\n",
    "   * length of the data is written first, followed by the actual data.\n",
    "   * This allows Avro to know exactly how many bytes to read for each value.\n",
    "     * Length: 2, Data: H, I \n",
    "*  For complex types like arrays or records, Avro uses the schema to determine the structure and types of nested values.\n",
    "*  Does not need to use special characters for delimiters, the encoding is more compact.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1779595",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pros and Cons\n",
    "\n",
    "* Pros:\n",
    "    * Binary data minimizes file size and maximizes efficiency\n",
    "    * A reliable support for schema evolution\n",
    "      * Supports new, missing, or changed fields.\n",
    "      * This allows old software to read new data, and new software to read old data\n",
    "      * It is a critical feature if your data can change.\n",
    "* Cons:\n",
    "    * Data is not human readable\n",
    "    * all the cons of a row-based format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf5eb9",
   "metadata": {},
   "source": [
    "### Analytical optimized Formats\n",
    "\n",
    "- In analytical queries, a  subset of all the available columns is often needed. \n",
    "  - With columnar storage, the system can read only the data of interest, skipping over irrelevant columns, which is much faster.\n",
    "    - Less data to read\n",
    "- With columnar formats, metadata about each chunk of data can be stored, allowing the query engine to skip over chunks that are irrelevant to the query, making data retrieval much faster.\n",
    "- Modern databases and data processing frameworks often use a technique called vectorized query execution. In this approach, operations are performed on an entire column at a time instead of row-by-row, exploiting modern CPU architecture for data-level parallelism.\n",
    "\n",
    "\n",
    "Query Performance:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db76c104-5f18-441a-8d84-d2a90cdd2788",
   "metadata": {},
   "source": [
    "### Introduction to Parquet\n",
    "\n",
    "* Parquet is a specialized file format designed for efficient storage and querying of large datasets.\n",
    "* It's fast for read operations\n",
    "    * Reading a specific column doesn't require scanning the entire file.\n",
    "    * Column-based storage enables faster query performance due to vectorized reading.\n",
    "* Similar data in columns allows for efficient compression algorithms.\n",
    "* allows schema evolution.\n",
    "* Initially developed by Twitter and Cloudera.\n",
    "* Now an open-source project under Apache Software Foundation.\n",
    "* Especially useful for data with a large number of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127e492",
   "metadata": {},
   "source": [
    "### Anatomy of a Parquet File\n",
    "* File Metadata: The starting point of the file, contains metadata like schema.\n",
    "* Column Chunks: Data is organized into sets of columns, each set called a chunk.\n",
    "* Row Groups: Each chunk can be split further into row groups to optimize reads.\n",
    "* Metadata: Contains file statistics and optional key-value pairs for custom metadata.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4fd74",
   "metadata": {},
   "source": [
    "### Data Context\n",
    "* \n",
    "Suppose you have a simplified dataset with the following columns:\n",
    "\n",
    "  * Transaction_ID (e.g., 001, 002, ...)\n",
    "  * Time (e.g., 10:01, 10:02, ...)\n",
    "  * Number_of_Items_Purchased (e.g., 4, 2, ...)\n",
    "  * Transaction_Total (e.g., 20.50, 10.00, ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ea231-2b26-4fd7-9bf6-e8c6b01e444a",
   "metadata": {},
   "source": [
    "### File Header\n",
    "\n",
    "* The File Header provides the Parquet version and schema information. \n",
    "  * It essentially lays out what kinds of columns (and their data types) the reader should expect. \n",
    "```\n",
    "message transaction_schema {\n",
    "  required int64 Transaction_ID;\n",
    "  required binary Time (UTF8);\n",
    "  required int32 Number_of_Items_Purchased;\n",
    "  required double Transaction_Total;\n",
    "  required binary City (UTF8);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa82da-3d9f-4794-97b2-ac670369a69b",
   "metadata": {},
   "source": [
    "### Column Chunks\n",
    "* Column Chunks are contiguous blocks of data from a single column. \n",
    "* In our example, one Column Chunk might store a million Transaction_ID values\n",
    "* another might store a million Time values, and so on.\n",
    "```\n",
    "Column Chunk for Transaction_ID: [T001, T002, ... (up to 1,000,000  entries)]\n",
    "Column Chunk for Time: [10:01, 10:02, ... (up to 1,000,000  entries)]\n",
    "Column Chunk for Number_of_Items_Purchased: [1, 2, ... (up to 1,000,000  entries)]\n",
    "Column Chunk for Transaction_Total: [20.50, 10.00, ... (up to 1,000,000  entries)]\n",
    "Column Chunk for City: [Honolulu, Montreal, ... (up to 1,000,000  entries)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4714fa-6bb7-4e8b-8ea7-91760864fd10",
   "metadata": {},
   "source": [
    "### Row Groups\n",
    "\n",
    "* Row groups bundle together a subset of Column Chunks to make reads more efficient. \n",
    "  * Each Row Group includes a set of Column Chunks, \n",
    "    * i.e., column for a subset of rows. \n",
    "\n",
    "* ex. Row Group 1 might contain the first million records for each column\n",
    "```\n",
    "Row Group 1:\n",
    "  - Column Chunk 1 for Time: [10:01, 10:02, ... (up to 1,000,000 entries)]\n",
    "  - Column Chunk 1 for Number_of_Items_Purchased: [1, 2, ... (up to 1,000,000 entries)]\n",
    "  - Column Chunk 1 for Transaction_Total: [20.50, 10.00, ... (up to 1,000,000 entries)]\n",
    "  - Column Chunk 1 for City: [Honoluly, montreal, ... (up to 1,000,000 entries)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c354d9-170e-4b78-bd40-f48c2d40d7a0",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "* Contains information that helps in reading and interpreting the data effectively. \n",
    "\n",
    "* This can include:\n",
    "  * Summary statistics (e.g., min and max values for each column)\n",
    "  * Compression type used for each column\n",
    "  * Optional custom key-value pairs, ex. `{ \"regions\": \"north-america\", \"requested-by\": \"john\"}`\n",
    "  * Schema definitions.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e57f9e-1f42-4bbb-9395-40b5fd609a26",
   "metadata": {},
   "source": [
    "### Data Partitioning in Parquet\n",
    "\n",
    "* Basic Partitioning: Data can be divided into sub-folders based on a column value.\n",
    "* Nested Partitions: You can create partitions within partitions based on multiple columns.\n",
    "* Example Folder Structure, where we're  split on the similar values of the MONTH  or department\n",
    "\n",
    "```python\n",
    "/root_directory  \n",
    "    /HOUR=10\n",
    "        CITY=HONOLULU\n",
    "           data..\n",
    "        CITY=MONTREAL\n",
    "            data..\n",
    "        \n",
    "    /HOUR=11\n",
    "        CITY=HONOLULU\n",
    "           data..\n",
    "        CITY=MONTREAL\n",
    "            data..\n",
    "\n",
    "    ...      \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ee793-78d3-4cc2-a41d-60a63bab06e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Analytics and Reading Data\n",
    "\n",
    "* If you've partitioned your data well, you generally will not have to read all the files.\n",
    "  * Read the partitions that are relevant to your query. \n",
    "  * For instance, if you're interested in transactions that occurred in the 10:00 hour, you would only read the files under the /Hour=10 directory.\n",
    "\n",
    "* High-level tools that can manage partitions and fetch only relevant data when using Parquet include:\n",
    "\n",
    " * Apache Spark (covered later in class), Presto (open-source distributed SQL) Amazon Athena (based on Presto and optimized for Amazon S3), \n",
    " * Many other open source or commercial high-level tools and query engines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b6bdf-006c-4bad-88d6-960e5dbf9717",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exmaple: python\n",
    "\n",
    "\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Parquet Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read all data from a Parquet file\n",
    "df = spark.read.parquet(\"/root_directory/\")\n",
    "\n",
    "# Filter to only include data where Hour equals 10\n",
    "df_filtered = df.filter(df.Hour == 10)\n",
    "\n",
    "# Optionally, you can show the filtered DataFrame\n",
    "df_filtered.show() ,.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6738b-730f-4b51-a360-f1ad17e027be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### Exmaple: Athena or Presto (SQL)\n",
    "```SQL\n",
    "SELECT * FROM \"database\".\"table\" WHERE Hour = '10';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498e882",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PARQUET PROS and CONS\n",
    "\n",
    "* Pros: \n",
    " * Highly compressible since data is stored column-wise (compression rates up to 75%)\n",
    "   * Can use different compression algorithms with different datatypes\n",
    " * Seamless splittability across columns.\n",
    " * Optimized for reading data and ideal for read-intensive tasks\n",
    "   * Can use parallelization to read different columns.\n",
    "\n",
    "* Cons:\n",
    " * Very slow at writing data and not good with write-intensive applications\n",
    " * Does not support updates on the data as Parquet files are immutable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7031cd0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Memory Mapping for Working with Large Files\n",
    "\n",
    "* Memory Mapping is a technique to map either a segment or an entire file from disk into virtual memory.\n",
    "  * Links a file on disk directly to a section of virtual memory.\n",
    "* Only the necessary portions of a file are loaded into RAM, as and when needed making efficient use of memory.\n",
    "* Allows programs to work with files larger than available physical RAM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb2372",
   "metadata": {},
   "source": [
    "### Reading a File From Disk\n",
    "\n",
    "1. An application initiates a read() system call, moving the request from user space to kernel space.\n",
    "2. The kernel instructs the hardware to fetch the needed data from the disk.\n",
    "3. Data is loaded into a kernel buffer, often via Direct Memory Access (DMA) to bypass CPU involvement.\n",
    "4. Kernel copies data to a user-space buffer specified in the read() call.\n",
    "  * Kernel Buffers: Optimized for system tasks, reside in privileged memory.\n",
    "  * User-Space Buffers: For application tasks, accessible by the application.\n",
    "5. Application proceeds with its logic in user space, using the data in its buffer.\n",
    "6. A write() system call copies data from user space to a kernel socket buffer.\n",
    "7. Kernel writes this data to the hardware.\n",
    "8. Hardware confirms the completion of the write operation to the kernel.\n",
    "9. write() system call returns, completing the write operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9bcfdd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### READ FILE\n",
    "\n",
    "![](https://www.dropbox.com/s/0uaxprebndgw1sn/read_file.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2429b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Memory Mapping a File From Disk\n",
    "\n",
    "* `mmap()`: A System Call for Memory Mapping\n",
    "  * This system call requests the mapping of a file into the application's address space.\n",
    "  * The request transitions from user space to kernel space to establish the mapping.\n",
    "* The kernel communicates with the hardware to map the relevant file data into a memory section (RAM).\n",
    "  * This is typically done \"lazily,\" meaning data may not be loaded until accessed.\n",
    "* Once the mapping is set up, the application can directly access and modify the data as if it were in its own memory space.\n",
    "* If data in the mapped memory region is altered, the kernel will eventually flush these changes back to the hardware.\n",
    "  * The operating system optimizes the timing of this flush based on various factors like system load and other I/O operations.\n",
    "* `munmap()`:  This system call is used to unmap a previously mapped memory section.\n",
    "  * It signals the kernel to remove the mapping and release the resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67ee70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MMAP\n",
    "![](https://www.dropbox.com/s/eezmaerp24s45s8/mmap.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29232a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `time` Command: Overview\n",
    "\n",
    "The OS tracks time spent executing a program, broken down into CPU times and Wall time.\n",
    "\n",
    "* CPU Times: The CPU's work time on your task.\n",
    "  * User Time: Time spent executing your code.\n",
    "  * System Time: Time on system tasks like memory allocation.\n",
    "  * Total Time: Sum of User and System Time.\n",
    "* Wall Time: Real-world elapsed time for your command.\n",
    "\n",
    "* Important Notes:\n",
    "  * Wall Time can be < CPU Time due to multitasking.\n",
    "  * Wall Time can be > CPU Time because of \"idle time\" (e.g., waiting for disk reads or network data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb0da6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `time` Command: Refresher\n",
    "\n",
    "* In a Jupyter Notebook, %time and %%time are magic commands that help you measure the execution time of code, but they are used in slightly different contexts:\n",
    "\n",
    "\n",
    "* `%time` is used for timing a single line of code. \n",
    "```python\n",
    "%time x = sum(range(100))\n",
    "```\n",
    "* `%%time` is used to time the entire cell. \n",
    "```python\n",
    "# Meaures the complete block\n",
    "%%time\n",
    "x = sum(range(100))\n",
    "y = sum(range(200))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2304c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#!wget -P https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-06.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d69af33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17780075 entries, 0 to 17780074\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Dtype         \n",
      "---  ------                -----         \n",
      " 0   hvfhs_license_num     object        \n",
      " 1   dispatching_base_num  object        \n",
      " 2   originating_base_num  object        \n",
      " 3   request_datetime      datetime64[ns]\n",
      " 4   on_scene_datetime     datetime64[ns]\n",
      " 5   pickup_datetime       datetime64[ns]\n",
      " 6   dropoff_datetime      datetime64[ns]\n",
      " 7   PULocationID          int64         \n",
      " 8   DOLocationID          int64         \n",
      " 9   trip_miles            float64       \n",
      " 10  trip_time             int64         \n",
      " 11  base_passenger_fare   float64       \n",
      " 12  tolls                 float64       \n",
      " 13  bcf                   float64       \n",
      " 14  sales_tax             float64       \n",
      " 15  congestion_surcharge  float64       \n",
      " 16  airport_fee           float64       \n",
      " 17  tips                  float64       \n",
      " 18  driver_pay            float64       \n",
      " 19  shared_request_flag   object        \n",
      " 20  shared_match_flag     object        \n",
      " 21  access_a_ride_flag    object        \n",
      " 22  wav_request_flag      object        \n",
      " 23  wav_match_flag        object        \n",
      "dtypes: datetime64[ns](4), float64(9), int64(3), object(8)\n",
      "memory usage: 9.9 GB\n",
      "CPU times: user 12.9 s, sys: 1.32 s, total: 14.2 s\n",
      "Wall time: 9.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "data = pd.read_parquet(\"~/Downloads/fhvhv_tripdata_2022-06.parquet\")\n",
    "data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53348d06-ba65-42a0-8067-7dd5d13ae5ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 58s, sys: 3.6 s, total: 2min 2s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# data.to_csv(\"~/Downloads/fhvhv_tripdata_2022-06.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "267daafc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2209930419921875 gigabytes\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "def print_mem():\n",
    "    gig = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 3\n",
    "    print(f\"{gig} gigabytes\")\n",
    "print_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b5f72f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.2 s, sys: 3.33 s, total: 28.5 s\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%time df = pd.read_csv(\"~/Downloads/fhvhv_tripdata_2022-06.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de3c9f34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.629287719726562 gigabytes\n"
     ]
    }
   ],
   "source": [
    "print_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cc0f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85340381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.766876220703125 gigabytes\n"
     ]
    }
   ],
   "source": [
    "print_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318b5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b91c328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 419 µs, sys: 723 µs, total: 1.14 ms\n",
      "Wall time: 17.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_handle = open(\"/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.csv\", 'r+b') \n",
    "mmap_file = mmap.mmap(file_handle.fileno(), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bf4b7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.766632080078125 gigabytes\n"
     ]
    }
   ],
   "source": [
    "print_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87b60c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0:\tb',hvfhs_license_num,dispatching_base_num,originating_base_num,request_datetime,on_scene_datetime,pickup_datetime,dropoff_datetime,PULocationID,DOLocationID,trip_miles,trip_time,base_passenger_fare,tolls,bcf,sales_tax,congestion_surcharge,airport_fee,tips,driver_pay,shared_request_flag,shared_match_flag,access_a_ride_flag,wav_request_flag,wav_match_flag\\n'\n"
     ]
    }
   ],
   "source": [
    "line = mmap_file.readline()\n",
    "print(f\"Line 0:\\t{line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05c5ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1:\tb'0,HV0003,B03404,B03404,2022-06-01 00:15:35,2022-06-01 00:17:20,2022-06-01 00:17:41,2022-06-01 00:25:41,234,114,1.5,480,7.68,0.0,0.23,0.68,2.75,0.0,1.0,9.36,N,N, ,N,N\\n'\n"
     ]
    }
   ],
   "source": [
    "line = mmap_file.readline()\n",
    "print(f\"Line 1:\\t{line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29e648e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0:\tb',hvfhs_license_num,dispatching_base_num,originating_base_num,request_datetime,on_scene_datetime,pickup_datetime,dropoff_datetime,PULocationID,DOLocationID,trip_miles,trip_time,base_passenger_fare,tolls,bcf,sales_tax,congestion_surcharge,airport_fee,tips,driver_pay,shared_request_flag,shared_match_flag,access_a_ride_flag,wav_request_flag,wav_match_flag\\n'\n"
     ]
    }
   ],
   "source": [
    "mmap_file.seek(0)\n",
    "line = mmap_file.readline()\n",
    "print(f\"Line 0:\\t{line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "270e90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap_file.seek?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90049eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at 2:\tb'vfhs_license_num,dispatching_base_num,originating_base_num,request_datetime,on_scene_datetime,pickup_datetime,dropoff_datetime,PULocationID,DOLocationID,trip_miles,trip_time,base_passenger_fare,tolls,bcf,sales_tax,congestion_surcharge,airport_fee,tips,driver_pay,shared_request_flag,shared_match_flag,access_a_ride_flag,wav_request_flag,wav_match_flag\\n'\n"
     ]
    }
   ],
   "source": [
    "mmap_file.seek(2)\n",
    "line = mmap_file.readline()\n",
    "print(f\"Starting at 2:\\t{line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02dd78c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmap_file.seek(0)\n",
    "mmap_file.find(b'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dca0a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0,HV0003,B03404,B03404,2022-06-01 00:15:35,2022-06-01 00:17:20,2022-06-01 00:17:41,2022-06-01 00:25:41,234,114,1.5,480,7.68,0.0,0.23,0.68,2.75,0.0,1.0,9.36,N,N, ,N,N\\n'\n"
     ]
    }
   ],
   "source": [
    "mmap_file.seek(353+1)\n",
    "line = mmap_file.readline()\n",
    "print(f\"{line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6f258b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmap_file.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a74ff00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 263 ms, sys: 726 ms, total: 989 ms\n",
      "Wall time: 988 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2979703837"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = open(\"/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.csv\", 'r').read()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6784ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(mmap_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3aac3e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'location_key'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmap_file[0:12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77d9c950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'l', b'o', b'c', b'a', b't', b'i', b'o', b'n', b'_', b'k', b'e', b'y']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# almost equivalent to \n",
    "[x.to_bytes(1, 'big') for x in mmap_file[0:12]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e84a169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'location_key'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent to \n",
    "b''.join([x.to_bytes(1, 'big') for x in mmap_file[0:12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8caa67d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'location_key'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# almsot equivalent to \n",
    "\"\".join([chr(x) for x in mmap_file[0:12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410c2b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 s, sys: 366 ms, total: 2.11 s\n",
      "Wall time: 2.11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17780076"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_handle = open(\"/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.csv\", 'r+b') \n",
    "total_lines = 0 \n",
    "mmap_file = mmap.mmap(file_handle.fileno(), 0)\n",
    "while mmap_file.readline():\n",
    "    total_lines += 1\n",
    "total_lines        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "172f94cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101G\t/Users/mahdi/Downloads/aggregated_100.csv\r\n",
      "101G\ttotal\r\n"
     ]
    }
   ],
   "source": [
    "!du -sch ~/Downloads/aggregated_100.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a3488ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 232 µs, sys: 986 µs, total: 1.22 ms\n",
      "Wall time: 781 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_handle = open(\"/Users/mahdi/Downloads/aggregated_100.csv\", 'r+b') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ba3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.46 s, sys: 380 ms, total: 2.84 s\n",
      "Wall time: 2.85 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17780076"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "total_lines = 0 \n",
    "file_handle = open(\"/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.csv\",) \n",
    "while file_handle.readline():\n",
    "    total_lines += 1\n",
    "total_lines        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c385e09f-6a9a-4852-9ec3-15bf30f49ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following creates a csv file with randome fields with num_cols and 10M entrie\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import string\n",
    "\n",
    "num_rows = 10000000  # 10 million rows\n",
    "num_cols = 100  # 100 columns\n",
    "\n",
    "# This will generate a random string of length n\n",
    "def random_string(n=10):\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=n))\n",
    "\n",
    "# Open a new CSV file in write mode ('w')\n",
    "with open('large_file.csv', 'w', newline='', buffering=10485760) as csvfile:  # 10 MB buffer\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header\n",
    "    csv_writer.writerow([f\"Column_{i}\" for i in range(num_cols)])\n",
    "\n",
    "    # Write the rows\n",
    "    for _ in range(num_rows):\n",
    "        csv_writer.writerow([random_string() for _ in range(num_cols)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a21e3400-70c1-45fd-ac89-4e40f1ded3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.88 s, sys: 4.32 s, total: 6.2 s\n",
      "Wall time: 23.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_handle = open(\"large_file.csv\", 'r+b') \n",
    "total_lines = 0 \n",
    "mmap_file = mmap.mmap(file_handle.fileno(), 0)\n",
    "while mmap_file.readline():\n",
    "    total_lines += 1\n",
    "total_lines        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dbde451-1213-419b-b862-985d7729e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.84 s, sys: 1.43 s, total: 9.27 s\n",
      "Wall time: 9.36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "total_lines = 0 \n",
    "file_handle = open(\"large_file.csv\",) \n",
    "while file_handle.readline():\n",
    "    total_lines += 1\n",
    "total_lines        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecd86e25-95d7-42aa-ae7a-28bacd2bb73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.29 s, sys: 1.53 s, total: 5.82 s\n",
      "Wall time: 5.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\"large_file.csv\", 'r+b') as file_handle:\n",
    "    total_lines = 0\n",
    "    mmap_file = mmap.mmap(file_handle.fileno(), 0)\n",
    "    chunk_size = 1 << 17  # 64 KiB\n",
    "    while True:\n",
    "        chunk = mmap_file.read(chunk_size)\n",
    "        if not chunk:\n",
    "            break\n",
    "        total_lines += chunk.count(b'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab73fb-160b-4f18-b401-efdfdba8893d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
